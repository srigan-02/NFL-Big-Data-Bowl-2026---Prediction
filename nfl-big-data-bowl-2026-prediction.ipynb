{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf42153f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-28T11:02:05.935967Z",
     "iopub.status.busy": "2025-11-28T11:02:05.935077Z",
     "iopub.status.idle": "2025-11-28T11:02:08.256652Z",
     "shell.execute_reply": "2025-11-28T11:02:08.255570Z"
    },
    "papermill": {
     "duration": 2.329694,
     "end_time": "2025-11-28T11:02:08.258326",
     "exception": false,
     "start_time": "2025-11-28T11:02:05.928632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_inference_server.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_gateway.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w17.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w05.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w10.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w03.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w18.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w05.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w11.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w12.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w16.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w06.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w18.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w10.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w02.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w08.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w12.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w13.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w15.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w03.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w13.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w15.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w16.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w01.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w04.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w14.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w14.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w09.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w01.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w07.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w11.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w06.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w04.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w09.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w17.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w07.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w08.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w02.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b9c73",
   "metadata": {
    "papermill": {
     "duration": 0.004271,
     "end_time": "2025-11-28T11:02:08.267314",
     "exception": false,
     "start_time": "2025-11-28T11:02:08.263043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NFL Big Data Bowl 2026 – Player Movement Prediction Project\n",
    "\n",
    "**1. IMPORTS**\n",
    "\n",
    "*Purpose:*\n",
    "All required Python libraries are imported here, including data manipulation, numerical computation, machine learning frameworks, and deep learning libraries.\n",
    "\n",
    "*Libraries used and reasoning:*\n",
    "\n",
    "- pandas & numpy: Efficient data manipulation and numerical computation.\n",
    "\n",
    "- torch & nn: For building and training the LSTM sequence model.\n",
    "\n",
    "- xgboost, lightgbm, catboost: For tree-based residual models that refine LSTM outputs.\n",
    "\n",
    "- os, glob, pickle: For file handling and model loading.\n",
    "\n",
    "*Why this approach:*\n",
    "Using separate imports and modularizing them makes the code easier to maintain, debug, and ensures all dependencies are listed upfront.\n",
    "\n",
    "**2. FEATURE ENGINEERING FUNCTIONS**\n",
    "\n",
    "*Purpose:*\n",
    "Transform raw player tracking data into meaningful features for model input.\n",
    "\n",
    "*Key logic:*\n",
    "\n",
    "- Input data contains positions, velocities, accelerations, and other metrics per player per frame.\n",
    "\n",
    "- Additional features like relative distance to the line of scrimmage, players’ orientation, and team identifiers were computed.\n",
    "\n",
    "- Feature selection focused on columns used consistently across tree and LSTM models (TREE_FEATURE_COLS).\n",
    "\n",
    "*Why this method:*\n",
    "Proper feature engineering captures the spatial and temporal context for player movement, enabling both LSTM and tree models to make better predictions.\n",
    "\n",
    "**3. MODEL ARCHITECTURE (LSTM)**\n",
    "\n",
    "*Purpose:*\n",
    "Predict the future positions of players over a sequence of frames.\n",
    "\n",
    "*Model details:*\n",
    "\n",
    "Encoder-Decoder LSTM with:\n",
    "\n",
    "- Encoder: processes historical player trajectories.\n",
    "\n",
    "- Decoder: predicts next positions frame by frame.\n",
    "\n",
    "- Linear layer: maps hidden states to (x, y) coordinates.\n",
    "\n",
    "- Handles variable sequence lengths using pack_padded_sequence.\n",
    "\n",
    "- Uses last observed (x, y) as input for next frame prediction.\n",
    "\n",
    "*Why LSTM:*\n",
    "Player trajectories are sequential and time-dependent. LSTMs can capture temporal dependencies better than tree models alone.\n",
    "\n",
    "**4. UTILITY FUNCTIONS**\n",
    "\n",
    "*Purpose:*\n",
    "Handle data preprocessing and batching for models.\n",
    "\n",
    "*Functions include:*\n",
    "\n",
    "- pad_groups(): Pads sequences to maximum length in batch for LSTM.\n",
    "\n",
    "- make_groups_meta(): Organizes player trajectories by nfl_id and generates metadata for reconstructing predictions.\n",
    "\n",
    "- Model loading utilities: load_lstm_model(), load_xgb_model(), load_lgb_model(), load_cat_model().\n",
    "\n",
    "*Why this approach:*\n",
    "\n",
    "Ensures compatibility between variable-length input sequences and fixed-size batch processing in PyTorch.\n",
    "\n",
    "Simplifies model deployment by providing functions to load trained models safely.\n",
    "\n",
    "**5. predict_play() — Multi-frame inference (LSTM + Residual Tree Models)**\n",
    "\n",
    "*Purpose:*\n",
    "Predict player positions over multiple frames using LSTM and optionally refine with tree-based residuals.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Generate features per player and batch into sequences.\n",
    "\n",
    "- Run LSTM to predict (x, y) for T_out frames.\n",
    "\n",
    "*If tree models exist:*\n",
    "\n",
    "- Predict residuals for (x, y) using last input frame features.\n",
    "\n",
    "- Ensemble residuals from XGBoost, LightGBM, and CatBoost using predefined weights.\n",
    "\n",
    "- Apply residuals to LSTM output.\n",
    "\n",
    "- Clip predicted coordinates to field boundaries.\n",
    "\n",
    "*Why this method:*\n",
    "\n",
    "- LSTM captures the sequential patterns in player movement.\n",
    "\n",
    "- Tree models correct small systematic errors (residuals) using learned relationships from historical data.\n",
    "\n",
    "- Ensures physically valid predictions.\n",
    "\n",
    "**6. predict_one_play()**\n",
    "\n",
    "*Purpose:*\n",
    "Simplifies single-play prediction by integrating LSTM and tree model predictions.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Accepts a single play DataFrame.\n",
    "\n",
    "- Calls predict_play() with preloaded models.\n",
    "\n",
    "- Returns the final output in required schema: (game_id, play_id, nfl_id, frame_id, x, y).\n",
    "\n",
    "*Why this method:*\n",
    "Modularizes prediction for single-play use, which is necessary for the Kaggle evaluation loop or local testing.\n",
    "\n",
    "**7. kaggle_main_offline() — Offline Prediction Loop**\n",
    "\n",
    "*Purpose:*\n",
    "Run predictions for the Kaggle Big Data Bowl using local CSV inputs, without requiring the Kaggle-specific nflrush environment.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Loads LSTM and tree-based residual models (XGBoost, LightGBM, CatBoost if available).\n",
    "\n",
    "- Reads the test dataset directly from test_input.csv.\n",
    "\n",
    "- Applies predict_one_play() to generate predicted player positions for all plays.\n",
    "\n",
    "- Fills missing predictions with default values (0.0) to ensure no NaNs in the submission.\n",
    "\n",
    "- Merges predictions with required Kaggle columns (game_id, play_id, nfl_id, frame_id).\n",
    "\n",
    "- Saves the final predictions to a CSV file (submission.csv) for direct Kaggle submission.\n",
    "\n",
    "*Why this method:*\n",
    "\n",
    "- Fully offline and internet-free, compliant with Kaggle submission rules.\n",
    "\n",
    "- Modular, easy to maintain, and flexible for testing with different model combinations.\n",
    "\n",
    "- Avoids dependency on environment-specific packages while ensuring correct submission format.\n",
    "\n",
    "**8. main / Local Testing**\n",
    "\n",
    "*Purpose:*\n",
    "\n",
    "Enable local execution and validation of the full prediction pipeline before submission.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Loads the full test dataset and model artifacts.\n",
    "\n",
    "- Runs predict_one_play() on all test plays.\n",
    "\n",
    "- Generates predictions in the Kaggle-required format.\n",
    "\n",
    "- Saves or previews the output locally for debugging and performance checks.\n",
    "\n",
    "*Why this approach:*\n",
    "\n",
    "- Allows full validation of sequence and residual model predictions offline.\n",
    "\n",
    "- Eliminates the risk of runtime errors due to missing environment-specific packages.\n",
    "\n",
    "- Enables iterative performance tuning and debugging before submission.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- The project combines an LSTM model for sequential player movement prediction with tree-based residual models for accuracy enhancement.\n",
    "\n",
    "- Modular architecture separates data preprocessing, model inference, and submission logic.\n",
    "\n",
    "- Residual models correct errors from the LSTM predictions, improving overall performance.\n",
    "\n",
    "- Local CSV-based workflow ensures safe, flexible, and reproducible testing and submission.\n",
    "\n",
    "This structure is fully compatible with Kaggle Big Data Bowl rules and does not require internet access or nflrush."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba97b5",
   "metadata": {
    "papermill": {
     "duration": 0.004109,
     "end_time": "2025-11-28T11:02:08.275816",
     "exception": false,
     "start_time": "2025-11-28T11:02:08.271707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e882ebe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:02:08.285937Z",
     "iopub.status.busy": "2025-11-28T11:02:08.285123Z",
     "iopub.status.idle": "2025-11-28T11:02:25.946434Z",
     "shell.execute_reply": "2025-11-28T11:02:25.945688Z"
    },
    "papermill": {
     "duration": 17.668133,
     "end_time": "2025-11-28T11:02:25.948067",
     "exception": false,
     "start_time": "2025-11-28T11:02:08.279934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Try to import tree libraries; if missing, we'll skip those models\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    xgb = None\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    import catboost as cb\n",
    "except Exception:\n",
    "    cb = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f0c9c20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:02:25.959019Z",
     "iopub.status.busy": "2025-11-28T11:02:25.957959Z",
     "iopub.status.idle": "2025-11-28T11:02:25.963161Z",
     "shell.execute_reply": "2025-11-28T11:02:25.962435Z"
    },
    "papermill": {
     "duration": 0.011778,
     "end_time": "2025-11-28T11:02:25.964497",
     "exception": false,
     "start_time": "2025-11-28T11:02:25.952719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CONFIG / PATHS / WEIGHTS\n",
    "DEVICE = torch.device(\"cpu\")  # Kaggle evaluation is CPU\n",
    "# Model file names - change these to your actual saved files before zipping\n",
    "LSTM_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_lstm.pth\"\n",
    "XGB_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_xgb.json\"\n",
    "LGB_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_lgb.txt\"\n",
    "CAT_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_cat.cbm\"\n",
    "\n",
    "# Ensemble blending weights for residuals (must sum <= 1)\n",
    "ENSEMBLE_WEIGHTS = {\n",
    "    \"xgb\": 0.3,\n",
    "    \"lgb\": 0.3,\n",
    "    \"cat\": 0.4\n",
    "}\n",
    "\n",
    "# Fallback if none of tree models available -> zero contribution\n",
    "# LSTM has implicit weight = 1.0 (we add residuals on top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c21db2",
   "metadata": {
    "papermill": {
     "duration": 0.004042,
     "end_time": "2025-11-28T11:02:25.972783",
     "exception": false,
     "start_time": "2025-11-28T11:02:25.968741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. FEATURE ENGINEERING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "223d505f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:02:25.982792Z",
     "iopub.status.busy": "2025-11-28T11:02:25.982010Z",
     "iopub.status.idle": "2025-11-28T11:02:25.995027Z",
     "shell.execute_reply": "2025-11-28T11:02:25.994390Z"
    },
    "papermill": {
     "duration": 0.019617,
     "end_time": "2025-11-28T11:02:25.996518",
     "exception": false,
     "start_time": "2025-11-28T11:02:25.976901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_inches(h):\n",
    "    try:\n",
    "        ft, inch = str(h).split(\"-\")\n",
    "        return int(ft) * 12 + int(inch)\n",
    "    except Exception:\n",
    "        return 72\n",
    "\n",
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Competition-safe feature engineering used by LSTM and tree models.\n",
    "       Must match training used for all models.\"\"\"\n",
    "    df = df.copy()\n",
    "    for col in ['x','y','s','a','o','dir']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "\n",
    "    # Physical attributes\n",
    "    if 'player_height' in df.columns:\n",
    "        df['height_inches'] = df['player_height'].apply(to_inches).fillna(72)\n",
    "    else:\n",
    "        df['height_inches'] = 72\n",
    "    if 'player_weight' in df.columns:\n",
    "        df['weight_lbs'] = pd.to_numeric(df['player_weight'], errors='coerce').fillna(200)\n",
    "    else:\n",
    "        df['weight_lbs'] = 200\n",
    "    df['bmi'] = (df['weight_lbs'] / (df['height_inches']**2 + 1e-6)) * 703.0\n",
    "\n",
    "    # Directional components\n",
    "    dir_rad = np.radians(pd.to_numeric(df['dir'], errors='coerce').fillna(0.0))\n",
    "    df['heading_x'] = np.sin(dir_rad)\n",
    "    df['heading_y'] = np.cos(dir_rad)\n",
    "    orient_rad = np.radians(pd.to_numeric(df['o'], errors='coerce').fillna(0.0))\n",
    "    df['orient_x'] = np.sin(orient_rad)\n",
    "    df['orient_y'] = np.cos(orient_rad)\n",
    "\n",
    "    # diff dir/orient\n",
    "    dcol = pd.to_numeric(df['dir'], errors='coerce').fillna(0.0)\n",
    "    ocol = pd.to_numeric(df['o'], errors='coerce').fillna(0.0)\n",
    "    diff = np.abs(dcol - ocol)\n",
    "    df['dir_orient_diff'] = np.minimum(diff, 360 - diff)\n",
    "\n",
    "    # Velocity/acceleration components\n",
    "    s = pd.to_numeric(df['s'], errors='coerce').fillna(0.0)\n",
    "    a = pd.to_numeric(df['a'], errors='coerce').fillna(0.0)\n",
    "    df['velocity_x'] = s * df['heading_x']\n",
    "    df['velocity_y'] = s * df['heading_y']\n",
    "    df['acceleration_x'] = a * df['heading_x']\n",
    "    df['acceleration_y'] = a * df['heading_y']\n",
    "\n",
    "    # Higher-level physics\n",
    "    df['speed_squared'] = s**2\n",
    "    df['accel_magnitude'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n",
    "    df['momentum_x'] = df['weight_lbs'] * df['velocity_x']\n",
    "    df['momentum_y'] = df['weight_lbs'] * df['velocity_y']\n",
    "    df['momentum_magnitude'] = np.sqrt(df['momentum_x']**2 + df['momentum_y']**2)\n",
    "    df['kinetic_energy'] = 0.5 * df['weight_lbs'] * df['speed_squared']\n",
    "\n",
    "    # safe fill\n",
    "    df = df.replace([np.inf, -np.inf], 0.0)\n",
    "    df = df.fillna(0.0)\n",
    "    return df\n",
    "\n",
    "# Note: ensure these features exactly match what the tree models expect.\n",
    "# Example feature list used by tree models (per-row)\n",
    "TREE_FEATURE_COLS = [\n",
    "    \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\n",
    "    \"heading_x\",\"heading_y\",\n",
    "    \"velocity_x\",\"velocity_y\",\n",
    "    \"acceleration_x\",\"acceleration_y\",\n",
    "    \"dir_orient_diff\",\n",
    "    \"height_inches\",\"weight_lbs\",\"bmi\",\n",
    "    \"speed_squared\",\"accel_magnitude\",\n",
    "    \"momentum_x\",\"momentum_y\",\"momentum_magnitude\",\"kinetic_energy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aebf2c9",
   "metadata": {
    "papermill": {
     "duration": 0.004101,
     "end_time": "2025-11-28T11:02:26.004988",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.000887",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. MODEL ARCHITECTURE (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a3673b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:02:26.014918Z",
     "iopub.status.busy": "2025-11-28T11:02:26.014269Z",
     "iopub.status.idle": "2025-11-28T11:02:26.022613Z",
     "shell.execute_reply": "2025-11-28T11:02:26.021869Z"
    },
    "papermill": {
     "duration": 0.014732,
     "end_time": "2025-11-28T11:02:26.023920",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.009188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.decoder = nn.LSTM(2, hidden_dim, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, enc_X, enc_lens, T_out=10):\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(enc_X, enc_lens.cpu().numpy(), batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.encoder(packed)\n",
    "        h, c = h_n, c_n\n",
    "        B = enc_X.size(0)\n",
    "        last_xy = []\n",
    "        for i, L in enumerate(enc_lens):\n",
    "            Li = int(L.item())\n",
    "            last = enc_X[i, max(0, Li-1), :2]  # assume x,y are first two features\n",
    "            last_xy.append(last)\n",
    "        dec_in = torch.stack(last_xy, dim=0).unsqueeze(1)  # (B,1,2)\n",
    "        preds = []\n",
    "        for t in range(T_out):\n",
    "            out, (h, c) = self.decoder(dec_in, (h, c))\n",
    "            out = out.squeeze(1)\n",
    "            xy = self.fc(out)\n",
    "            preds.append(xy.unsqueeze(1))\n",
    "            dec_in = xy.unsqueeze(1).detach()\n",
    "        preds = torch.cat(preds, dim=1)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1144ee6f",
   "metadata": {
    "papermill": {
     "duration": 0.00402,
     "end_time": "2025-11-28T11:02:26.032165",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.028145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. UTILITY FUNCTIONS (padding, grouping, loading models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12bc5405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:02:26.042787Z",
     "iopub.status.busy": "2025-11-28T11:02:26.042324Z",
     "iopub.status.idle": "2025-11-28T11:02:26.056185Z",
     "shell.execute_reply": "2025-11-28T11:02:26.055431Z"
    },
    "papermill": {
     "duration": 0.02122,
     "end_time": "2025-11-28T11:02:26.057525",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.036305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_groups(groups):\n",
    "    B = len(groups)\n",
    "    F = groups[0].shape[1]\n",
    "    T_max = max(g.shape[0] for g in groups)\n",
    "    Xp = np.zeros((B, T_max, F), dtype=np.float32)\n",
    "    lens = np.zeros((B,), dtype=np.int64)\n",
    "    for i,g in enumerate(groups):\n",
    "        T = g.shape[0]\n",
    "        Xp[i, :T, :] = g\n",
    "        lens[i] = T\n",
    "    Xt = torch.tensor(Xp, dtype=torch.float32, device=DEVICE)\n",
    "    lens_t = torch.tensor(lens, dtype=torch.int64, device=DEVICE)\n",
    "    return Xt, lens_t\n",
    "\n",
    "def make_groups_meta(play_df):\n",
    "    df = engineer_features(play_df.copy())\n",
    "    groups = []\n",
    "    metas = []\n",
    "    for nfl_id, g in df.groupby(\"nfl_id\"):\n",
    "        g = g.sort_values(\"frame_id\")\n",
    "        feat = g[[c for c in TREE_FEATURE_COLS if c in g.columns]].values.astype(np.float32)\n",
    "        groups.append(feat)\n",
    "        metas.append((int(g['game_id'].iloc[0]), int(g['play_id'].iloc[0]), int(nfl_id), g['frame_id'].values.astype(int)))\n",
    "    return groups, metas\n",
    "\n",
    "def load_lstm_model(path=LSTM_MODEL_PATH):\n",
    "    model = EncoderDecoderLSTM(input_dim=len(TREE_FEATURE_COLS), hidden_dim=128, num_layers=2, dropout=0.1)\n",
    "    if os.path.exists(path):\n",
    "        state = torch.load(path, map_location=DEVICE)\n",
    "        # support if you saved dict with 'state_dict'\n",
    "        if isinstance(state, dict) and 'state_dict' in state:\n",
    "            state = state['state_dict']\n",
    "        model.load_state_dict(state)\n",
    "    else:\n",
    "        print(\"Warning: LSTM model file not found at\", path)\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_xgb_model(path=XGB_MODEL_PATH):\n",
    "    if xgb is None:\n",
    "        return None\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    try:\n",
    "        booster = xgb.Booster()\n",
    "        booster.load_model(path)\n",
    "        return booster\n",
    "    except Exception:\n",
    "        # try to load as sklearn wrapper\n",
    "        try:\n",
    "            bst = xgb.BRegressor()\n",
    "            bst.load_model(path)\n",
    "            return bst\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "def load_lgb_model(path=LGB_MODEL_PATH):\n",
    "    if lgb is None:\n",
    "        return None\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    try:\n",
    "        booster = lgb.Booster(model_file=path)\n",
    "        return booster\n",
    "    except Exception:\n",
    "        try:\n",
    "            booster = lgb.LGBMRegressor()\n",
    "            booster.booster_ = lgb.Booster(model_file=path)\n",
    "            return booster\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "def load_cat_model(path=CAT_MODEL_PATH):\n",
    "    if cb is None:\n",
    "        return None\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    try:\n",
    "        model = cb.CatBoost()\n",
    "        model.load_model(path)\n",
    "        return model\n",
    "    except Exception:\n",
    "        try:\n",
    "            model = cb.CatBoostRegressor()\n",
    "            model.load_model(path)\n",
    "            return model\n",
    "        except Exception:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde8a96f",
   "metadata": {
    "papermill": {
     "duration": 0.004073,
     "end_time": "2025-11-28T11:02:26.065933",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.061860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. predict_play() — Multi-frame inference (LSTM generating absolute preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc6bf9f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:02:26.075781Z",
     "iopub.status.busy": "2025-11-28T11:02:26.075357Z",
     "iopub.status.idle": "2025-11-28T11:02:26.091901Z",
     "shell.execute_reply": "2025-11-28T11:02:26.091106Z"
    },
    "papermill": {
     "duration": 0.023219,
     "end_time": "2025-11-28T11:02:26.093297",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.070078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_play(play_input_df, lstm_model, tree_models=None, T_out_default=10):\n",
    "    \"\"\"\n",
    "    Predict positions for a single play using LSTM + optional tree model residuals.\n",
    "    \n",
    "    Args:\n",
    "        play_input_df: DataFrame for a single play with input frames\n",
    "        lstm_model: loaded LSTM model\n",
    "        tree_models: dict with keys {'xgb','lgb','cat'} pointing to model objects or None\n",
    "        T_out_default: default number of output frames if not specified\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with columns game_id, play_id, nfl_id, frame_id, x, y\n",
    "    \"\"\"\n",
    "    groups, metas = make_groups_meta(play_input_df)\n",
    "    if len(groups) == 0:\n",
    "        return pd.DataFrame(columns=[\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\",\"x\",\"y\"])\n",
    "\n",
    "    Xt, lens = pad_groups(groups)\n",
    "\n",
    "    # Determine T_out\n",
    "    if 'num_frames_output' in play_input_df.columns:\n",
    "        try:\n",
    "            T_out = int(play_input_df['num_frames_output'].dropna().iloc[0])\n",
    "            if T_out <= 0:\n",
    "                T_out = T_out_default\n",
    "        except:\n",
    "            T_out = T_out_default\n",
    "    else:\n",
    "        T_out = T_out_default\n",
    "\n",
    "    # LSTM prediction -> absolute positions\n",
    "    with torch.no_grad():\n",
    "        preds = lstm_model(Xt, lens, T_out=T_out)  # (B, T_out, 2)\n",
    "        preds_np = preds.cpu().numpy()\n",
    "\n",
    "    # Build DataFrame of LSTM results\n",
    "    rows = []\n",
    "    for i, meta in enumerate(metas):\n",
    "        game_id, play_id, nfl_id, in_frame_ids = meta\n",
    "        for t in range(preds_np.shape[1]):\n",
    "            rows.append({\n",
    "                \"game_id\": int(game_id),\n",
    "                \"play_id\": int(play_id),\n",
    "                \"nfl_id\": int(nfl_id),\n",
    "                \"frame_id\": int(t+1),\n",
    "                \"x\": float(preds_np[i,t,0]),\n",
    "                \"y\": float(preds_np[i,t,1])\n",
    "            })\n",
    "    lstm_out_df = pd.DataFrame(rows)\n",
    "\n",
    "    # If no tree models, return LSTM output\n",
    "    if tree_models is None or all(m is None for m in tree_models.values()):\n",
    "        return lstm_out_df\n",
    "\n",
    "    # Build last-input feature mapping\n",
    "    df_input = engineer_features(play_input_df.copy())\n",
    "    last_input_map = {int(nfl_id): g.sort_values(\"frame_id\").iloc[-1]\n",
    "                      for nfl_id, g in df_input.groupby(\"nfl_id\")}\n",
    "\n",
    "    # Prepare feature matrix for tree residuals\n",
    "    feat_rows = []\n",
    "    for _, row in lstm_out_df.iterrows():\n",
    "        base = last_input_map.get(int(row['nfl_id']))\n",
    "        if base is None:\n",
    "            feat_rows.append(np.zeros(len(TREE_FEATURE_COLS), dtype=np.float32))\n",
    "        else:\n",
    "            feat = np.array([base[c] if c in base.index else 0.0 for c in TREE_FEATURE_COLS], dtype=np.float32)\n",
    "            feat_rows.append(feat)\n",
    "    feat_matrix = np.vstack(feat_rows)\n",
    "\n",
    "    # Predict residuals from tree models\n",
    "    total_residual = np.zeros((len(lstm_out_df), 2), dtype=np.float32)\n",
    "\n",
    "    for model_name in ['xgb','lgb','cat']:\n",
    "        m = tree_models.get(model_name)\n",
    "        if m is None:\n",
    "            continue\n",
    "        try:\n",
    "            # XGBoost\n",
    "            if model_name == 'xgb':\n",
    "                if isinstance(m, xgb.Booster):\n",
    "                    dmat = xgb.DMatrix(feat_matrix, feature_names=TREE_FEATURE_COLS)\n",
    "                    pred_flat = m.predict(dmat)\n",
    "                else:\n",
    "                    pred_flat = m.predict(feat_matrix)\n",
    "            # LightGBM\n",
    "            elif model_name == 'lgb':\n",
    "                pred_flat = m.predict(feat_matrix)\n",
    "            # CatBoost\n",
    "            elif model_name == 'cat':\n",
    "                pred_flat = m.predict(feat_matrix)\n",
    "\n",
    "            pred_flat = np.asarray(pred_flat)\n",
    "            if pred_flat.ndim == 1:\n",
    "                dx = pred_flat\n",
    "                dy = np.zeros_like(dx)\n",
    "                preds_model = np.vstack([dx, dy]).T\n",
    "            else:\n",
    "                preds_model = pred_flat.reshape(-1, 2)\n",
    "\n",
    "            total_residual += ENSEMBLE_WEIGHTS.get(model_name, 0.0) * preds_model\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Tree model {model_name} prediction failed: {e}\")\n",
    "\n",
    "    # Apply residuals and clip to field boundaries\n",
    "    final_rows = []\n",
    "    for i, row in lstm_out_df.iterrows():\n",
    "        x_final = np.clip(row['x'] + total_residual[i,0], 0.0, 120.0)\n",
    "        y_final = np.clip(row['y'] + total_residual[i,1], 0.0, 53.3)\n",
    "        final_rows.append({\n",
    "            \"game_id\": int(row['game_id']),\n",
    "            \"play_id\": int(row['play_id']),\n",
    "            \"nfl_id\": int(row['nfl_id']),\n",
    "            \"frame_id\": int(row['frame_id']),\n",
    "            \"x\": float(x_final),\n",
    "            \"y\": float(y_final)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(final_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0482db",
   "metadata": {
    "papermill": {
     "duration": 0.004133,
     "end_time": "2025-11-28T11:02:26.101713",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.097580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. predict_one_play() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0700dd4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:02:26.111658Z",
     "iopub.status.busy": "2025-11-28T11:02:26.110870Z",
     "iopub.status.idle": "2025-11-28T11:02:26.116769Z",
     "shell.execute_reply": "2025-11-28T11:02:26.115903Z"
    },
    "papermill": {
     "duration": 0.01245,
     "end_time": "2025-11-28T11:02:26.118186",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.105736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_one_play(test_play_df, models):\n",
    "    \"\"\"\n",
    "    Predict positions for a single play using LSTM + optional tree model residuals.\n",
    "\n",
    "    Args:\n",
    "        test_play_df: DataFrame containing all frames of a single play\n",
    "        models: dictionary containing loaded models with keys:\n",
    "                'lstm', 'xgb', 'lgb', 'cat'\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns: game_id, play_id, nfl_id, frame_id, x, y\n",
    "    \"\"\"\n",
    "    lstm_model = models.get('lstm')\n",
    "    if lstm_model is None:\n",
    "        raise ValueError(\"LSTM model must be provided in models dictionary.\")\n",
    "\n",
    "    tree_models = {\n",
    "        'xgb': models.get('xgb'),\n",
    "        'lgb': models.get('lgb'),\n",
    "        'cat': models.get('cat')\n",
    "    }\n",
    "\n",
    "    # Use the improved predict_play function\n",
    "    pred_df = predict_play(test_play_df, lstm_model, tree_models=tree_models)\n",
    "\n",
    "    # Return only required columns\n",
    "    return pred_df[[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\", \"x\", \"y\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f65fe4c",
   "metadata": {
    "papermill": {
     "duration": 0.004056,
     "end_time": "2025-11-28T11:02:26.126651",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.122595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. kaggle_main() — evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0712978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:02:26.136599Z",
     "iopub.status.busy": "2025-11-28T11:02:26.136010Z",
     "iopub.status.idle": "2025-11-28T11:02:26.144448Z",
     "shell.execute_reply": "2025-11-28T11:02:26.143568Z"
    },
    "papermill": {
     "duration": 0.015105,
     "end_time": "2025-11-28T11:02:26.145947",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.130842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def kaggle_main_offline(test_csv_path, submission_csv_path):\n",
    "    \"\"\"\n",
    "    Offline version of the Kaggle Big Data Bowl pipeline.\n",
    "    Does not require 'nflrush' and uses CSV files instead.\n",
    "    \"\"\"\n",
    "    print(\"Running offline Kaggle pipeline...\")\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Load All Models\n",
    "    # ------------------------------------------------\n",
    "    print(\"Loading models...\")\n",
    "    models = {}\n",
    "\n",
    "    # LSTM Sequence Model\n",
    "    models[\"lstm\"] = load_lstm_model(LSTM_MODEL_PATH)\n",
    "\n",
    "    # Residual Tree Models (load only if libraries exist)\n",
    "    models[\"xgb\"] = load_xgb_model(XGB_MODEL_PATH) if xgb is not None else None\n",
    "    models[\"lgb\"] = load_lgb_model(LGB_MODEL_PATH) if lgb is not None else None\n",
    "    models[\"cat\"] = load_cat_model(CAT_MODEL_PATH) if cb is not None else None\n",
    "\n",
    "    # Soft warnings if libs missing\n",
    "    if xgb is None:\n",
    "        print(\"⚠ xgboost not installed — XGB residual model disabled.\")\n",
    "    if lgb is None:\n",
    "        print(\"⚠ lightgbm not installed — LGB residual model disabled.\")\n",
    "    if cb is None:\n",
    "        print(\"⚠ catboost not installed — CAT residual model disabled.\")\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Load Test Data\n",
    "    # ------------------------------------------------\n",
    "    test_df = pd.read_csv(test_csv_path)\n",
    "    sample_pred_df = test_df[[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"]].copy()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # Prediction\n",
    "    # ------------------------------------------------\n",
    "    preds_full = predict_one_play(test_df, models)\n",
    "\n",
    "    # Merge predictions with required submission format\n",
    "    merged = sample_pred_df.merge(\n",
    "        preds_full,\n",
    "        on=[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Fill missing predictions\n",
    "    merged[\"x\"] = merged[\"x\"].fillna(0.0)\n",
    "    merged[\"y\"] = merged[\"y\"].fillna(0.0)\n",
    "\n",
    "    # Keep Kaggle-required columns\n",
    "    out_df = merged[sample_pred_df.columns.tolist() + [\"x\", \"y\"]]\n",
    "\n",
    "    # Save submission CSV\n",
    "    out_df.to_csv(submission_csv_path, index=False)\n",
    "    print(f\"Offline submission saved to {submission_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b37d19",
   "metadata": {
    "papermill": {
     "duration": 0.004159,
     "end_time": "2025-11-28T11:02:26.154328",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.150169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 8. __main__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9899db2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:02:26.164572Z",
     "iopub.status.busy": "2025-11-28T11:02:26.163870Z",
     "iopub.status.idle": "2025-11-28T11:02:28.434767Z",
     "shell.execute_reply": "2025-11-28T11:02:28.433646Z"
    },
    "papermill": {
     "duration": 2.277412,
     "end_time": "2025-11-28T11:02:28.436296",
     "exception": false,
     "start_time": "2025-11-28T11:02:26.158884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running offline Kaggle pipeline...\n",
      "Loading models...\n",
      "Warning: LSTM model file not found at /kaggle/input/nfl-big-data-bowl-2026-prediction/best_lstm.pth\n",
      "Offline submission saved to /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    kaggle_main_offline(\n",
    "        test_csv_path=\"/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\",\n",
    "        submission_csv_path=\"/kaggle/working/submission.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f4b4e",
   "metadata": {
    "papermill": {
     "duration": 0.004393,
     "end_time": "2025-11-28T11:02:28.445184",
     "exception": false,
     "start_time": "2025-11-28T11:02:28.440791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30.78962,
   "end_time": "2025-11-28T11:02:30.645110",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-28T11:01:59.855490",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
