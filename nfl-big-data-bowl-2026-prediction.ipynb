{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d09498b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-01T10:34:18.409953Z",
     "iopub.status.busy": "2025-12-01T10:34:18.409621Z",
     "iopub.status.idle": "2025-12-01T10:34:21.116169Z",
     "shell.execute_reply": "2025-12-01T10:34:21.115003Z"
    },
    "papermill": {
     "duration": 2.715259,
     "end_time": "2025-12-01T10:34:21.118150",
     "exception": false,
     "start_time": "2025-12-01T10:34:18.402891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_inference_server.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_gateway.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w17.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w05.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w10.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w03.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w18.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w05.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w11.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w12.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w16.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w06.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w18.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w10.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w02.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w08.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w12.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w13.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w15.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w03.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w13.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w15.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w16.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w01.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w04.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w14.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w14.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w09.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w01.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w07.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w11.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w06.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w04.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w09.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w17.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w07.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w08.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w02.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e1f16d",
   "metadata": {
    "papermill": {
     "duration": 0.003898,
     "end_time": "2025-12-01T10:34:21.126896",
     "exception": false,
     "start_time": "2025-12-01T10:34:21.122998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NFL Big Data Bowl 2026 – Player Movement Prediction Project\n",
    "\n",
    "**1. IMPORTS**\n",
    "\n",
    "*Purpose:*\n",
    "All required Python libraries are imported here, including data manipulation, numerical computation, machine learning frameworks, and deep learning libraries.\n",
    "\n",
    "*Libraries used and reasoning:*\n",
    "\n",
    "- pandas & numpy: Efficient data manipulation and numerical computation.\n",
    "\n",
    "- torch & nn: For building and training the LSTM sequence model.\n",
    "\n",
    "- xgboost, lightgbm, catboost: For tree-based residual models that refine LSTM outputs.\n",
    "\n",
    "- os, glob, pickle: For file handling and model loading.\n",
    "\n",
    "*Why this approach:*\n",
    "Using separate imports and modularizing them makes the code easier to maintain, debug, and ensures all dependencies are listed upfront.\n",
    "\n",
    "**2. FEATURE ENGINEERING FUNCTIONS**\n",
    "\n",
    "*Purpose:*\n",
    "Transform raw player tracking data into meaningful features for model input.\n",
    "\n",
    "*Key logic:*\n",
    "\n",
    "- Input data contains positions, velocities, accelerations, and other metrics per player per frame.\n",
    "\n",
    "- Additional features like relative distance to the line of scrimmage, players’ orientation, and team identifiers were computed.\n",
    "\n",
    "- Feature selection focused on columns used consistently across tree and LSTM models (TREE_FEATURE_COLS).\n",
    "\n",
    "*Why this method:*\n",
    "Proper feature engineering captures the spatial and temporal context for player movement, enabling both LSTM and tree models to make better predictions.\n",
    "\n",
    "**3. MODEL ARCHITECTURE (LSTM)**\n",
    "\n",
    "*Purpose:*\n",
    "Predict the future positions of players over a sequence of frames.\n",
    "\n",
    "*Model details:*\n",
    "\n",
    "Encoder-Decoder LSTM with:\n",
    "\n",
    "- Encoder: processes historical player trajectories.\n",
    "\n",
    "- Decoder: predicts next positions frame by frame.\n",
    "\n",
    "- Linear layer: maps hidden states to (x, y) coordinates.\n",
    "\n",
    "- Handles variable sequence lengths using pack_padded_sequence.\n",
    "\n",
    "- Uses last observed (x, y) as input for next frame prediction.\n",
    "\n",
    "*Why LSTM:*\n",
    "Player trajectories are sequential and time-dependent. LSTMs can capture temporal dependencies better than tree models alone.\n",
    "\n",
    "**4. UTILITY FUNCTIONS**\n",
    "\n",
    "*Purpose:*\n",
    "Handle data preprocessing and batching for models.\n",
    "\n",
    "*Functions include:*\n",
    "\n",
    "- pad_groups(): Pads sequences to maximum length in batch for LSTM.\n",
    "\n",
    "- make_groups_meta(): Organizes player trajectories by nfl_id and generates metadata for reconstructing predictions.\n",
    "\n",
    "- Model loading utilities: load_lstm_model(), load_xgb_model(), load_lgb_model(), load_cat_model().\n",
    "\n",
    "*Why this approach:*\n",
    "\n",
    "Ensures compatibility between variable-length input sequences and fixed-size batch processing in PyTorch.\n",
    "\n",
    "Simplifies model deployment by providing functions to load trained models safely.\n",
    "\n",
    "**5. predict_play() — Multi-frame inference (LSTM + Residual Tree Models)**\n",
    "\n",
    "*Purpose:*\n",
    "Predict player positions over multiple frames using LSTM and optionally refine with tree-based residuals.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Generate features per player and batch into sequences.\n",
    "\n",
    "- Run LSTM to predict (x, y) for T_out frames.\n",
    "\n",
    "*If tree models exist:*\n",
    "\n",
    "- Predict residuals for (x, y) using last input frame features.\n",
    "\n",
    "- Ensemble residuals from XGBoost, LightGBM, and CatBoost using predefined weights.\n",
    "\n",
    "- Apply residuals to LSTM output.\n",
    "\n",
    "- Clip predicted coordinates to field boundaries.\n",
    "\n",
    "*Why this method:*\n",
    "\n",
    "- LSTM captures the sequential patterns in player movement.\n",
    "\n",
    "- Tree models correct small systematic errors (residuals) using learned relationships from historical data.\n",
    "\n",
    "- Ensures physically valid predictions.\n",
    "\n",
    "**6. predict_one_play()**\n",
    "\n",
    "*Purpose:*\n",
    "Simplifies single-play prediction by integrating LSTM and tree model predictions.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Accepts a single play DataFrame.\n",
    "\n",
    "- Calls predict_play() with preloaded models.\n",
    "\n",
    "- Returns the final output in required schema: (game_id, play_id, nfl_id, frame_id, x, y).\n",
    "\n",
    "*Why this method:*\n",
    "Modularizes prediction for single-play use, which is necessary for the Kaggle evaluation loop or local testing.\n",
    "\n",
    "**7. kaggle_main_offline() — Offline Prediction Loop**\n",
    "\n",
    "*Purpose:*\n",
    "Run predictions for the Kaggle Big Data Bowl using local CSV inputs, without requiring the Kaggle-specific nflrush environment.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Loads LSTM and tree-based residual models (XGBoost, LightGBM, CatBoost if available).\n",
    "\n",
    "- Reads the test dataset directly from test_input.csv.\n",
    "\n",
    "- Applies predict_one_play() to generate predicted player positions for all plays.\n",
    "\n",
    "- Fills missing predictions with default values (0.0) to ensure no NaNs in the submission.\n",
    "\n",
    "- Merges predictions with required Kaggle columns (game_id, play_id, nfl_id, frame_id).\n",
    "\n",
    "- Saves the final predictions to a CSV file (submission.csv) for direct Kaggle submission.\n",
    "\n",
    "*Why this method:*\n",
    "\n",
    "- Fully offline and internet-free, compliant with Kaggle submission rules.\n",
    "\n",
    "- Modular, easy to maintain, and flexible for testing with different model combinations.\n",
    "\n",
    "- Avoids dependency on environment-specific packages while ensuring correct submission format.\n",
    "\n",
    "**8. main / Local Testing**\n",
    "\n",
    "*Purpose:*\n",
    "\n",
    "Enable local execution and validation of the full prediction pipeline before submission.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Loads the full test dataset and model artifacts.\n",
    "\n",
    "- Runs predict_one_play() on all test plays.\n",
    "\n",
    "- Generates predictions in the Kaggle-required format.\n",
    "\n",
    "- Saves or previews the output locally for debugging and performance checks.\n",
    "\n",
    "*Why this approach:*\n",
    "\n",
    "- Allows full validation of sequence and residual model predictions offline.\n",
    "\n",
    "- Eliminates the risk of runtime errors due to missing environment-specific packages.\n",
    "\n",
    "- Enables iterative performance tuning and debugging before submission.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- The project combines an LSTM model for sequential player movement prediction with tree-based residual models for accuracy enhancement.\n",
    "\n",
    "- Modular architecture separates data preprocessing, model inference, and submission logic.\n",
    "\n",
    "- Residual models correct errors from the LSTM predictions, improving overall performance.\n",
    "\n",
    "- Local CSV-based workflow ensures safe, flexible, and reproducible testing and submission.\n",
    "\n",
    "This structure is fully compatible with Kaggle Big Data Bowl rules and does not require internet access or nflrush."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c08e82",
   "metadata": {
    "papermill": {
     "duration": 0.004423,
     "end_time": "2025-12-01T10:34:21.135329",
     "exception": false,
     "start_time": "2025-12-01T10:34:21.130906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "666a4ade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:34:21.145512Z",
     "iopub.status.busy": "2025-12-01T10:34:21.144526Z",
     "iopub.status.idle": "2025-12-01T10:34:41.884276Z",
     "shell.execute_reply": "2025-12-01T10:34:41.883061Z"
    },
    "papermill": {
     "duration": 20.74703,
     "end_time": "2025-12-01T10:34:41.886381",
     "exception": false,
     "start_time": "2025-12-01T10:34:21.139351",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Optional tree libraries\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    xgb = None\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    import catboost as cb\n",
    "except Exception:\n",
    "    cb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "045ffab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:34:41.897050Z",
     "iopub.status.busy": "2025-12-01T10:34:41.896411Z",
     "iopub.status.idle": "2025-12-01T10:34:41.903510Z",
     "shell.execute_reply": "2025-12-01T10:34:41.902375Z"
    },
    "papermill": {
     "duration": 0.014498,
     "end_time": "2025-12-01T10:34:41.905177",
     "exception": false,
     "start_time": "2025-12-01T10:34:41.890679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# If you have model artifacts, put them under /kaggle/input/... or change these paths.\n",
    "LSTM_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_lstm.pth\"\n",
    "XGB_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_xgb.json\"\n",
    "LGB_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_lgb.txt\"\n",
    "CAT_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_cat.cbm\"\n",
    "\n",
    "ENSEMBLE_WEIGHTS = {\"xgb\": 0.3, \"lgb\": 0.3, \"cat\": 0.4}\n",
    "\n",
    "# -------------------------\n",
    "# Utility / FE functions\n",
    "# -------------------------\n",
    "def to_inches(h):\n",
    "    try:\n",
    "        ft, inch = str(h).split(\"-\")\n",
    "        return int(ft) * 12 + int(inch)\n",
    "    except Exception:\n",
    "        return 72\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8734fad0",
   "metadata": {
    "papermill": {
     "duration": 0.003989,
     "end_time": "2025-12-01T10:34:41.913440",
     "exception": false,
     "start_time": "2025-12-01T10:34:41.909451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. FEATURE ENGINEERING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3261413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:34:41.923405Z",
     "iopub.status.busy": "2025-12-01T10:34:41.923059Z",
     "iopub.status.idle": "2025-12-01T10:34:41.936000Z",
     "shell.execute_reply": "2025-12-01T10:34:41.934769Z"
    },
    "papermill": {
     "duration": 0.020361,
     "end_time": "2025-12-01T10:34:41.937751",
     "exception": false,
     "start_time": "2025-12-01T10:34:41.917390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create physics-based features used by LSTM / tree models.\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # ensure required columns\n",
    "    for col in ['x', 'y', 's', 'a', 'o', 'dir', 'player_height', 'player_weight', 'frame_id', 'nfl_id', 'game_id', 'play_id']:\n",
    "        if col not in df.columns:\n",
    "            # don't override required id columns if not present; but set defaults for FE\n",
    "            if col in ['x', 'y', 's', 'a', 'o', 'dir']:\n",
    "                df[col] = 0.0\n",
    "\n",
    "    # heights & weight\n",
    "    df['height_inches'] = df.get('player_height', '0').apply(to_inches).fillna(72)\n",
    "    df['weight_lbs'] = pd.to_numeric(df.get('player_weight', 200), errors='coerce').fillna(200)\n",
    "\n",
    "    # BMI\n",
    "    df['bmi'] = (df['weight_lbs'] / (df['height_inches']**2 + 1e-6)) * 703.0\n",
    "\n",
    "    # directions -> vectors\n",
    "    dir_rad = np.radians(pd.to_numeric(df['dir'], errors='coerce').fillna(0.0))\n",
    "    df['heading_x'] = np.sin(dir_rad)\n",
    "    df['heading_y'] = np.cos(dir_rad)\n",
    "\n",
    "    orient_rad = np.radians(pd.to_numeric(df['o'], errors='coerce').fillna(0.0))\n",
    "    df['orient_x'] = np.sin(orient_rad)\n",
    "    df['orient_y'] = np.cos(orient_rad)\n",
    "\n",
    "    dcol = pd.to_numeric(df['dir'], errors='coerce').fillna(0.0)\n",
    "    ocol = pd.to_numeric(df['o'], errors='coerce').fillna(0.0)\n",
    "    diff = np.abs(dcol - ocol)\n",
    "    df['dir_orient_diff'] = np.minimum(diff, 360 - diff)\n",
    "\n",
    "    s = pd.to_numeric(df['s'], errors='coerce').fillna(0.0)\n",
    "    a = pd.to_numeric(df['a'], errors='coerce').fillna(0.0)\n",
    "\n",
    "    df['velocity_x'] = s * df['heading_x']\n",
    "    df['velocity_y'] = s * df['heading_y']\n",
    "    df['acceleration_x'] = a * df['heading_x']\n",
    "    df['acceleration_y'] = a * df['heading_y']\n",
    "\n",
    "    df['speed_squared'] = s**2\n",
    "    df['accel_magnitude'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n",
    "\n",
    "    df['momentum_x'] = df['weight_lbs'] * df['velocity_x']\n",
    "    df['momentum_y'] = df['weight_lbs'] * df['velocity_y']\n",
    "    df['momentum_magnitude'] = np.sqrt(df['momentum_x']**2 + df['momentum_y']**2)\n",
    "\n",
    "    df['kinetic_energy'] = 0.5 * df['weight_lbs'] * df['speed_squared']\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
    "    return df\n",
    "\n",
    "\n",
    "TREE_FEATURE_COLS = [\n",
    "    \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\n",
    "    \"heading_x\",\"heading_y\",\n",
    "    \"velocity_x\",\"velocity_y\",\n",
    "    \"acceleration_x\",\"acceleration_y\",\n",
    "    \"dir_orient_diff\",\n",
    "    \"height_inches\",\"weight_lbs\",\"bmi\",\n",
    "    \"speed_squared\",\"accel_magnitude\",\n",
    "    \"momentum_x\",\"momentum_y\",\"momentum_magnitude\",\"kinetic_energy\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f085b5f8",
   "metadata": {
    "papermill": {
     "duration": 0.003937,
     "end_time": "2025-12-01T10:34:41.945950",
     "exception": false,
     "start_time": "2025-12-01T10:34:41.942013",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. MODEL ARCHITECTURE (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4def07f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:34:41.955446Z",
     "iopub.status.busy": "2025-12-01T10:34:41.955106Z",
     "iopub.status.idle": "2025-12-01T10:34:41.964705Z",
     "shell.execute_reply": "2025-12-01T10:34:41.963690Z"
    },
    "papermill": {
     "duration": 0.016439,
     "end_time": "2025-12-01T10:34:41.966435",
     "exception": false,
     "start_time": "2025-12-01T10:34:41.949996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                               batch_first=True, dropout=dropout)\n",
    "        self.decoder = nn.LSTM(2, hidden_dim, num_layers=num_layers,\n",
    "                               batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, enc_X, enc_lens, T_out=10):\n",
    "        # enc_X shape: (B, T, F)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            enc_X, enc_lens.cpu().numpy(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (h_n, c_n) = self.encoder(packed)\n",
    "        h, c = h_n, c_n\n",
    "\n",
    "        # build last observed x,y for each sequence\n",
    "        B = enc_X.size(0)\n",
    "        last_xy = []\n",
    "        for i, L in enumerate(enc_lens):\n",
    "            Li = int(L.item())\n",
    "            last_xy.append(enc_X[i, max(0, Li-1), :2])\n",
    "        dec_in = torch.stack(last_xy, dim=0).unsqueeze(1)  # (B,1,2)\n",
    "\n",
    "        preds = []\n",
    "        for t in range(T_out):\n",
    "            out, (h, c) = self.decoder(dec_in, (h, c))\n",
    "            xy = self.fc(out.squeeze(1))\n",
    "            preds.append(xy.unsqueeze(1))\n",
    "            dec_in = xy.unsqueeze(1).detach()\n",
    "        preds = torch.cat(preds, dim=1)  # (B, T_out, 2)\n",
    "        return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ab41ab",
   "metadata": {
    "papermill": {
     "duration": 0.003961,
     "end_time": "2025-12-01T10:34:41.974569",
     "exception": false,
     "start_time": "2025-12-01T10:34:41.970608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. UTILITY FUNCTIONS (padding, grouping, loading models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58648a2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:34:41.984069Z",
     "iopub.status.busy": "2025-12-01T10:34:41.983714Z",
     "iopub.status.idle": "2025-12-01T10:34:41.999239Z",
     "shell.execute_reply": "2025-12-01T10:34:41.998322Z"
    },
    "papermill": {
     "duration": 0.02249,
     "end_time": "2025-12-01T10:34:42.001048",
     "exception": false,
     "start_time": "2025-12-01T10:34:41.978558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# Padding & grouping utilities\n",
    "# -------------------------\n",
    "def pad_groups(groups):\n",
    "    \"\"\"Pad list of (T_i, F) arrays to (B, T_max, F) and return torch tensors + lens\"\"\"\n",
    "    B = len(groups)\n",
    "    F = groups[0].shape[1]\n",
    "    T_max = max(g.shape[0] for g in groups)\n",
    "\n",
    "    Xp = np.zeros((B, T_max, F), dtype=np.float32)\n",
    "    lens = np.zeros((B,), dtype=np.int64)\n",
    "    for i, g in enumerate(groups):\n",
    "        T = g.shape[0]\n",
    "        Xp[i, :T, :] = g\n",
    "        lens[i] = T\n",
    "    Xt = torch.tensor(Xp, dtype=torch.float32, device=DEVICE)\n",
    "    lens_t = torch.tensor(lens, dtype=torch.int64, device=DEVICE)\n",
    "    return Xt, lens_t\n",
    "\n",
    "\n",
    "def make_groups_meta(play_df):\n",
    "    \"\"\"Return (groups, metas) where groups is list of feature arrays per nfl_id\n",
    "       and metas contains (game_id, play_id, nfl_id, frame_ids_array).\"\"\"\n",
    "    df = engineer_features(play_df.copy())\n",
    "    groups, metas = [], []\n",
    "    for nfl_id, g in df.groupby(\"nfl_id\"):\n",
    "        g = g.sort_values(\"frame_id\")\n",
    "        # keep only features needed (ordered)\n",
    "        feat = g[[c for c in TREE_FEATURE_COLS if c in g.columns]].values.astype(np.float32)\n",
    "        groups.append(feat)\n",
    "        metas.append((\n",
    "            int(g['game_id'].iloc[0]),\n",
    "            int(g['play_id'].iloc[0]),\n",
    "            int(nfl_id),\n",
    "            g['frame_id'].values.astype(int)\n",
    "        ))\n",
    "    return groups, metas\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Model loading functions\n",
    "# -------------------------\n",
    "def load_lstm_model(path=LSTM_MODEL_PATH):\n",
    "    model = EncoderDecoderLSTM(input_dim=len(TREE_FEATURE_COLS))\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            state = torch.load(path, map_location=DEVICE)\n",
    "            if isinstance(state, dict) and 'state_dict' in state:\n",
    "                state = state['state_dict']\n",
    "            model.load_state_dict(state)\n",
    "        except Exception as e:\n",
    "            print(\"⚠ Failed to load LSTM state_dict:\", e)\n",
    "    else:\n",
    "        print(\"⚠ LSTM model missing at:\", path)\n",
    "    model.to(DEVICE).eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_xgb_model(path=XGB_MODEL_PATH):\n",
    "    if xgb is None or (not os.path.exists(path)):\n",
    "        return None\n",
    "    try:\n",
    "        booster = xgb.Booster()\n",
    "        booster.load_model(path)\n",
    "        return booster\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_lgb_model(path=LGB_MODEL_PATH):\n",
    "    if lgb is None or (not os.path.exists(path)):\n",
    "        return None\n",
    "    try:\n",
    "        return lgb.Booster(model_file=path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_cat_model(path=CAT_MODEL_PATH):\n",
    "    if cb is None or (not os.path.exists(path)):\n",
    "        return None\n",
    "    try:\n",
    "        m = cb.CatBoostRegressor()\n",
    "        m.load_model(path)\n",
    "        return m\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8d97b",
   "metadata": {
    "papermill": {
     "duration": 0.003932,
     "end_time": "2025-12-01T10:34:42.009169",
     "exception": false,
     "start_time": "2025-12-01T10:34:42.005237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. predict_play() — Multi-frame inference (LSTM generating absolute preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dfaa358",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:34:42.018643Z",
     "iopub.status.busy": "2025-12-01T10:34:42.018313Z",
     "iopub.status.idle": "2025-12-01T10:34:42.037549Z",
     "shell.execute_reply": "2025-12-01T10:34:42.036368Z"
    },
    "papermill": {
     "duration": 0.026112,
     "end_time": "2025-12-01T10:34:42.039217",
     "exception": false,
     "start_time": "2025-12-01T10:34:42.013105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_play(play_input_df, lstm_model, tree_models=None, T_out_default=10):\n",
    "    \"\"\"\n",
    "    Predict positions for one play (all players in play_input_df).\n",
    "    Returns DataFrame with columns game_id, play_id, nfl_id, frame_id, x, y\n",
    "    \"\"\"\n",
    "    groups, metas = make_groups_meta(play_input_df)\n",
    "    if len(groups) == 0:\n",
    "        return pd.DataFrame(columns=[\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\",\"x\",\"y\"])\n",
    "\n",
    "    Xt, lens = pad_groups(groups)\n",
    "\n",
    "    # choose T_out (default fallback)\n",
    "    if 'num_frames_output' in play_input_df.columns:\n",
    "        try:\n",
    "            T_out = int(play_input_df['num_frames_output'].dropna().iloc[0])\n",
    "            if T_out <= 0:\n",
    "                T_out = T_out_default\n",
    "        except Exception:\n",
    "            T_out = T_out_default\n",
    "    else:\n",
    "        T_out = T_out_default\n",
    "\n",
    "    # LSTM predictions\n",
    "    with torch.no_grad():\n",
    "        preds = lstm_model(Xt, lens, T_out=T_out)  # (B, T_out, 2)\n",
    "        preds_np = preds.cpu().numpy()\n",
    "\n",
    "    # Build LSTM output rows\n",
    "    rows = []\n",
    "    for i, meta in enumerate(metas):\n",
    "        game_id, play_id, nfl_id, _ = meta\n",
    "        for t in range(preds_np.shape[1]):\n",
    "            rows.append({\n",
    "                \"game_id\": int(game_id),\n",
    "                \"play_id\": int(play_id),\n",
    "                \"nfl_id\": int(nfl_id),\n",
    "                \"frame_id\": int(t+1),\n",
    "                \"x\": float(preds_np[i,t,0]),\n",
    "                \"y\": float(preds_np[i,t,1])\n",
    "            })\n",
    "    lstm_out_df = pd.DataFrame(rows)\n",
    "\n",
    "    # If no tree residual models -> return LSTM result\n",
    "    if tree_models is None or all(m is None for m in tree_models.values()):\n",
    "        return lstm_out_df\n",
    "\n",
    "    # Build feature matrix (use last observed frame per player)\n",
    "    df_input = engineer_features(play_input_df.copy())\n",
    "    last_input_map = {}\n",
    "    for nfl_id, g in df_input.groupby(\"nfl_id\"):\n",
    "        last_input_map[int(nfl_id)] = g.sort_values(\"frame_id\").iloc[-1]\n",
    "\n",
    "    feat_rows = []\n",
    "    for _, row in lstm_out_df.iterrows():\n",
    "        base = last_input_map.get(int(row['nfl_id']))\n",
    "        if base is None:\n",
    "            feat_rows.append(np.zeros(len(TREE_FEATURE_COLS), dtype=np.float32))\n",
    "        else:\n",
    "            feat_rows.append(np.array([base[c] if c in base.index else 0.0 for c in TREE_FEATURE_COLS], dtype=np.float32))\n",
    "    feat_matrix = np.vstack(feat_rows) if len(feat_rows) > 0 else np.zeros((0, len(TREE_FEATURE_COLS)), dtype=np.float32)\n",
    "\n",
    "    # Aggregate residuals\n",
    "    total_residual = np.zeros((len(lstm_out_df), 2), dtype=np.float32)\n",
    "    for name, m in tree_models.items():\n",
    "        if m is None: \n",
    "            continue\n",
    "        try:\n",
    "            if name == 'xgb':\n",
    "                if isinstance(m, xgb.Booster):\n",
    "                    dmat = xgb.DMatrix(feat_matrix, feature_names=TREE_FEATURE_COLS)\n",
    "                    pred_flat = m.predict(dmat)\n",
    "                else:\n",
    "                    pred_flat = m.predict(feat_matrix)\n",
    "            else:\n",
    "                pred_flat = m.predict(feat_matrix)\n",
    "\n",
    "            pred_flat = np.asarray(pred_flat)\n",
    "            if pred_flat.ndim == 1:\n",
    "                # assume single-output dx -> dy zero\n",
    "                dx = pred_flat\n",
    "                dy = np.zeros_like(dx)\n",
    "                preds_model = np.vstack([dx, dy]).T\n",
    "            else:\n",
    "                preds_model = pred_flat.reshape(-1, 2)\n",
    "            total_residual += ENSEMBLE_WEIGHTS.get(name, 0.0) * preds_model\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: tree model {name} failed to predict: {e}\")\n",
    "\n",
    "    # Apply residuals\n",
    "    final_rows = []\n",
    "    for i, row in lstm_out_df.iterrows():\n",
    "        x_final = float(np.clip(row['x'] + total_residual[i,0], 0.0, 120.0))\n",
    "        y_final = float(np.clip(row['y'] + total_residual[i,1], 0.0, 53.3))\n",
    "        final_rows.append({\n",
    "            \"game_id\": int(row['game_id']),\n",
    "            \"play_id\": int(row['play_id']),\n",
    "            \"nfl_id\": int(row['nfl_id']),\n",
    "            \"frame_id\": int(row['frame_id']),\n",
    "            \"x\": x_final,\n",
    "            \"y\": y_final\n",
    "        })\n",
    "    return pd.DataFrame(final_rows)\n",
    "\n",
    "\n",
    "def predict_one_play(test_play_df, models):\n",
    "    \"\"\"Wrapper expecting a single-play DataFrame (frames of that play).\"\"\"\n",
    "    lstm_model = models.get('lstm')\n",
    "    if lstm_model is None:\n",
    "        raise ValueError(\"LSTM model is required in models dict.\")\n",
    "    tree_models = {k: models.get(k) for k in ['xgb','lgb','cat']}\n",
    "    preds = predict_play(test_play_df, lstm_model, tree_models)\n",
    "    return preds[['game_id','play_id','nfl_id','frame_id','x','y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7582fd36",
   "metadata": {
    "papermill": {
     "duration": 0.003894,
     "end_time": "2025-12-01T10:34:42.047114",
     "exception": false,
     "start_time": "2025-12-01T10:34:42.043220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. kaggle_main() — evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "864edc50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:34:42.057377Z",
     "iopub.status.busy": "2025-12-01T10:34:42.056985Z",
     "iopub.status.idle": "2025-12-01T10:34:49.961619Z",
     "shell.execute_reply": "2025-12-01T10:34:49.960567Z"
    },
    "papermill": {
     "duration": 7.912126,
     "end_time": "2025-12-01T10:34:49.963328",
     "exception": false,
     "start_time": "2025-12-01T10:34:42.051202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[offline] loading models...\n",
      "⚠ LSTM model missing at: /kaggle/input/nfl-big-data-bowl-2026-prediction/best_lstm.pth\n",
      "[offline] models ready.\n",
      "[offline] reading test_input.csv ...\n",
      "[offline] test_input rows: 49753\n",
      "[offline] reading test.csv ...\n",
      "[offline] test spec rows: 5837\n",
      "[offline] submission saved to: /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# Kaggle server-style predict(test, test_input) - required for evaluator\n",
    "# -------------------------\n",
    "# We'll implement a `predict` function that works with polars or pandas inputs.\n",
    "# The evaluator passes:\n",
    "#   test: DataFrame listing rows to predict (game_id, play_id, nfl_id, frame_id)\n",
    "#   test_input: DataFrame containing input frames for each play (pre-pass frames)\n",
    "#\n",
    "# This function loads models on first call and returns predictions aligned to 'test' rows.\n",
    "_models_loaded = False\n",
    "_models_cache = None\n",
    "\n",
    "def _load_models_once():\n",
    "    global _models_loaded, _models_cache\n",
    "    if _models_loaded:\n",
    "        return\n",
    "    models = {}\n",
    "    print(\"[predict] loading models...\")\n",
    "    models['lstm'] = load_lstm_model(LSTM_MODEL_PATH)\n",
    "    models['xgb'] = load_xgb_model(XGB_MODEL_PATH)\n",
    "    models['lgb'] = load_lgb_model(LGB_MODEL_PATH)\n",
    "    models['cat'] = load_cat_model(CAT_MODEL_PATH)\n",
    "    _models_cache = models\n",
    "    _models_loaded = True\n",
    "    print(\"[predict] models loaded.\")\n",
    "\n",
    "def predict(test, test_input):\n",
    "    \"\"\"\n",
    "    Kaggle evaluation API signature: predict(test, test_input)\n",
    "    Accepts polars.DataFrame or pandas.DataFrame. Returns a polars.DataFrame or pandas DataFrame\n",
    "    with columns ['x','y'] aligned in the SAME order as the `test` argument.\n",
    "    \"\"\"\n",
    "    # lazy model load\n",
    "    if not _models_loaded:\n",
    "        _load_models_once()\n",
    "    models = _models_cache\n",
    "\n",
    "    # convert polars -> pandas if needed\n",
    "    try:\n",
    "        import polars as pl\n",
    "        is_polars = isinstance(test, pl.DataFrame)\n",
    "    except Exception:\n",
    "        is_polars = False\n",
    "\n",
    "    if is_polars:\n",
    "        test_pd = test.to_pandas()\n",
    "        test_input_pd = test_input.to_pandas()\n",
    "    else:\n",
    "        test_pd = test.copy()\n",
    "        test_input_pd = test_input.copy()\n",
    "\n",
    "    # Build mapping of play inputs (grouped by game_id, play_id)\n",
    "    input_groups = {k: g.sort_values('frame_id') for k,g in test_input_pd.groupby(['game_id','play_id'])}\n",
    "\n",
    "    # We'll produce predictions for every play present in test (which lists rows)\n",
    "    # For efficiency, iterate unique plays referenced in `test_pd`\n",
    "    preds_rows = []\n",
    "    # precompute sample_pred rows order so we return predictions aligned to test order\n",
    "    # test contains multiple rows per play (game_id, play_id, nfl_id, frame_id)\n",
    "    test_indexed = test_pd.reset_index(drop=True)\n",
    "    test_indexed['_row_idx'] = np.arange(len(test_indexed))\n",
    "\n",
    "    # collect predicted outputs per play into a dict for quick lookup\n",
    "    play_pred_map = {}  # key: (game_id, play_id) -> dataframe of predictions\n",
    "\n",
    "    for (gid, pid), group in test_pd.groupby(['game_id','play_id']):\n",
    "        key = (int(gid), int(pid))\n",
    "        if key not in input_groups:\n",
    "            # No input frames available for this play (rare). We'll output zeros for these rows later.\n",
    "            play_pred_map[key] = None\n",
    "            continue\n",
    "        play_input_df = input_groups[key]\n",
    "        # predict for this play (this returns predictions for all nfl_ids in play_input_df)\n",
    "        try:\n",
    "            out_df = predict_one_play(play_input_df, models)\n",
    "            # out_df uses frame_id starting at 1..T_out - ensure dtype alignment\n",
    "            play_pred_map[key] = out_df\n",
    "        except Exception as e:\n",
    "            print(f\"[predict] Warning: prediction failed for play {key}: {e}\")\n",
    "            play_pred_map[key] = None\n",
    "\n",
    "    # Now build a list of predictions aligned to 'test_pd' rows\n",
    "    pred_x = np.zeros(len(test_pd), dtype=np.float32)\n",
    "    pred_y = np.zeros(len(test_pd), dtype=np.float32)\n",
    "\n",
    "    for idx, row in test_pd.reset_index(drop=True).iterrows():\n",
    "        gid = int(row['game_id'])\n",
    "        pid = int(row['play_id'])\n",
    "        nid = int(row['nfl_id'])\n",
    "        fid = int(row['frame_id'])\n",
    "        key = (gid, pid)\n",
    "        out_df = play_pred_map.get(key)\n",
    "        if out_df is None or len(out_df) == 0:\n",
    "            # fallback: use last observed x,y for nfl_id in input if available, else 0.0\n",
    "            try:\n",
    "                input_play = input_groups[key]\n",
    "                last = input_play[input_play['nfl_id'] == nid].sort_values('frame_id')\n",
    "                if len(last) > 0:\n",
    "                    last_pos = last.iloc[-1]\n",
    "                    pred_x[idx] = float(last_pos.get('x', 0.0))\n",
    "                    pred_y[idx] = float(last_pos.get('y', 0.0))\n",
    "                else:\n",
    "                    pred_x[idx] = 0.0\n",
    "                    pred_y[idx] = 0.0\n",
    "            except Exception:\n",
    "                pred_x[idx] = 0.0\n",
    "                pred_y[idx] = 0.0\n",
    "        else:\n",
    "            # find row in out_df for same nfl_id and frame_id\n",
    "            sel = out_df[(out_df['nfl_id'] == nid) & (out_df['frame_id'] == fid)]\n",
    "            if len(sel) == 0:\n",
    "                # maybe prediction uses different frame indexing; try closest frame\n",
    "                sel_close = out_df[(out_df['nfl_id'] == nid)]\n",
    "                if len(sel_close) > 0:\n",
    "                    # pick row with same index order: try t-th predicted frame where t = fid-1 if available else last\n",
    "                    # safe approach: use last predicted frame for this nfl_id\n",
    "                    srow = sel_close.sort_values('frame_id').iloc[-1]\n",
    "                    pred_x[idx] = float(srow['x'])\n",
    "                    pred_y[idx] = float(srow['y'])\n",
    "                else:\n",
    "                    pred_x[idx] = 0.0\n",
    "                    pred_y[idx] = 0.0\n",
    "            else:\n",
    "                pred_x[idx] = float(sel.iloc[0]['x'])\n",
    "                pred_y[idx] = float(sel.iloc[0]['y'])\n",
    "\n",
    "    # Build DataFrame to return in same order as input 'test'\n",
    "    out_df = pd.DataFrame({\"x\": pred_x, \"y\": pred_y})\n",
    "\n",
    "    # Convert back to Polars if original was polars\n",
    "    try:\n",
    "        import polars as pl\n",
    "        if is_polars:\n",
    "            return pl.from_pandas(out_df)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return out_df\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Offline driver to create CSV submission locally\n",
    "# -------------------------\n",
    "def kaggle_main_offline(test_input_path, test_csv_path, submission_out_path):\n",
    "    \"\"\"\n",
    "    Offline inference using local CSVs:\n",
    "      - test_input.csv : frames for inference (play inputs)\n",
    "      - test.csv : sample predictions (rows we must predict)\n",
    "    Creates submission_out_path CSV with columns matching test.csv plus x,y.\n",
    "    \"\"\"\n",
    "    print(\"[offline] loading models...\")\n",
    "    models = {}\n",
    "    models['lstm'] = load_lstm_model(LSTM_MODEL_PATH)\n",
    "    models['xgb'] = load_xgb_model(XGB_MODEL_PATH)\n",
    "    models['lgb'] = load_lgb_model(LGB_MODEL_PATH)\n",
    "    models['cat'] = load_cat_model(CAT_MODEL_PATH)\n",
    "    print(\"[offline] models ready.\")\n",
    "\n",
    "    print(\"[offline] reading test_input.csv ...\")\n",
    "    df_input = pd.read_csv(test_input_path)\n",
    "    print(f\"[offline] test_input rows: {len(df_input)}\")\n",
    "\n",
    "    print(\"[offline] reading test.csv ...\")\n",
    "    sample_spec = pd.read_csv(test_csv_path)\n",
    "    print(f\"[offline] test spec rows: {len(sample_spec)}\")\n",
    "\n",
    "    # Build mapping of play -> predictions (cache)\n",
    "    input_groups = {k: g.sort_values('frame_id') for k,g in df_input.groupby(['game_id','play_id'])}\n",
    "\n",
    "    pred_rows = []\n",
    "    for (gid, pid), grp in sample_spec.groupby(['game_id','play_id']):\n",
    "        key = (int(gid), int(pid))\n",
    "        if key not in input_groups:\n",
    "            # no input frames for this play -> fill zeros for requested rows\n",
    "            for _, r in grp.iterrows():\n",
    "                pred_rows.append({\n",
    "                    \"game_id\": r['game_id'],\n",
    "                    \"play_id\": r['play_id'],\n",
    "                    \"nfl_id\": r['nfl_id'],\n",
    "                    \"frame_id\": r['frame_id'],\n",
    "                    \"x\": 0.0,\n",
    "                    \"y\": 0.0\n",
    "                })\n",
    "            continue\n",
    "\n",
    "        play_input_df = input_groups[key]\n",
    "        try:\n",
    "            out_df = predict_one_play(play_input_df, models)\n",
    "        except Exception as e:\n",
    "            print(f\"[offline] warning: predict failed for play {key}: {e}\")\n",
    "            out_df = pd.DataFrame(columns=[\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\",\"x\",\"y\"])\n",
    "\n",
    "        # Merge requested rows for this play with predicted rows\n",
    "        merged = grp.merge(out_df, on=['game_id','play_id','nfl_id','frame_id'], how='left')\n",
    "        # fill missing with last observed or zero\n",
    "        for idx, row in merged.iterrows():\n",
    "            x = row.get('x', np.nan)\n",
    "            y = row.get('y', np.nan)\n",
    "            if pd.isna(x) or pd.isna(y):\n",
    "                # fallback: last observed in play_input_df for this nfl_id\n",
    "                nid = int(row['nfl_id'])\n",
    "                last = play_input_df[play_input_df['nfl_id'] == nid].sort_values('frame_id')\n",
    "                if len(last) > 0:\n",
    "                    lastpos = last.iloc[-1]\n",
    "                    x = float(lastpos.get('x', 0.0))\n",
    "                    y = float(lastpos.get('y', 0.0))\n",
    "                else:\n",
    "                    x = 0.0\n",
    "                    y = 0.0\n",
    "            pred_rows.append({\n",
    "                \"game_id\": int(row['game_id']),\n",
    "                \"play_id\": int(row['play_id']),\n",
    "                \"nfl_id\": int(row['nfl_id']),\n",
    "                \"frame_id\": int(row['frame_id']),\n",
    "                \"x\": float(x),\n",
    "                \"y\": float(y)\n",
    "            })\n",
    "\n",
    "    submission = pd.DataFrame(pred_rows)\n",
    "    # ensure same ordering/columns as sample_spec\n",
    "    submission = submission.merge(sample_spec[['game_id','play_id','nfl_id','frame_id']], on=['game_id','play_id','nfl_id','frame_id'], how='right')\n",
    "    # final fill any remaining NaNs (defensive)\n",
    "    submission['x'] = submission['x'].fillna(0.0)\n",
    "    submission['y'] = submission['y'].fillna(0.0)\n",
    "\n",
    "    submission.to_csv(submission_out_path, index=False)\n",
    "    print(\"[offline] submission saved to:\", submission_out_path)\n",
    "    return submission\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Entry point for local runs\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # local/offline usage\n",
    "    TEST_INPUT = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\"\n",
    "    TEST_CSV = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\"\n",
    "    OUT = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "    if (os.path.exists(TEST_INPUT) and os.path.exists(TEST_CSV)):\n",
    "        kaggle_main_offline(TEST_INPUT, TEST_CSV, OUT)\n",
    "    else:\n",
    "        print(\"Offline test files not found; if running inside Kaggle evaluator, implement `predict(test, test_input)` entrypoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cc265",
   "metadata": {
    "papermill": {
     "duration": 0.004814,
     "end_time": "2025-12-01T10:34:49.976351",
     "exception": false,
     "start_time": "2025-12-01T10:34:49.971537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.160267,
   "end_time": "2025-12-01T10:34:52.695037",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T10:34:11.534770",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
