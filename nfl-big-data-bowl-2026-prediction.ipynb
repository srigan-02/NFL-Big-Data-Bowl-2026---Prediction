{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac537ea",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-01T09:49:36.799314Z",
     "iopub.status.busy": "2025-12-01T09:49:36.799003Z",
     "iopub.status.idle": "2025-12-01T09:49:39.337134Z",
     "shell.execute_reply": "2025-12-01T09:49:39.335960Z"
    },
    "papermill": {
     "duration": 2.545849,
     "end_time": "2025-12-01T09:49:39.339170",
     "exception": false,
     "start_time": "2025-12-01T09:49:36.793321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_inference_server.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_gateway.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w17.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w05.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w10.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w03.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w18.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w05.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w11.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w12.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w16.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w06.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w18.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w10.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w02.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w08.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w12.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w13.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w15.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w03.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w13.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w15.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w16.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w01.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w04.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w14.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w14.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w09.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w01.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w07.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w11.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w06.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w04.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w09.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w17.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w07.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w08.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w02.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab719983",
   "metadata": {
    "papermill": {
     "duration": 0.003546,
     "end_time": "2025-12-01T09:49:39.346667",
     "exception": false,
     "start_time": "2025-12-01T09:49:39.343121",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NFL Big Data Bowl 2026 – Player Movement Prediction Project\n",
    "\n",
    "**1. IMPORTS**\n",
    "\n",
    "*Purpose:*\n",
    "All required Python libraries are imported here, including data manipulation, numerical computation, machine learning frameworks, and deep learning libraries.\n",
    "\n",
    "*Libraries used and reasoning:*\n",
    "\n",
    "- pandas & numpy: Efficient data manipulation and numerical computation.\n",
    "\n",
    "- torch & nn: For building and training the LSTM sequence model.\n",
    "\n",
    "- xgboost, lightgbm, catboost: For tree-based residual models that refine LSTM outputs.\n",
    "\n",
    "- os, glob, pickle: For file handling and model loading.\n",
    "\n",
    "*Why this approach:*\n",
    "Using separate imports and modularizing them makes the code easier to maintain, debug, and ensures all dependencies are listed upfront.\n",
    "\n",
    "**2. FEATURE ENGINEERING FUNCTIONS**\n",
    "\n",
    "*Purpose:*\n",
    "Transform raw player tracking data into meaningful features for model input.\n",
    "\n",
    "*Key logic:*\n",
    "\n",
    "- Input data contains positions, velocities, accelerations, and other metrics per player per frame.\n",
    "\n",
    "- Additional features like relative distance to the line of scrimmage, players’ orientation, and team identifiers were computed.\n",
    "\n",
    "- Feature selection focused on columns used consistently across tree and LSTM models (TREE_FEATURE_COLS).\n",
    "\n",
    "*Why this method:*\n",
    "Proper feature engineering captures the spatial and temporal context for player movement, enabling both LSTM and tree models to make better predictions.\n",
    "\n",
    "**3. MODEL ARCHITECTURE (LSTM)**\n",
    "\n",
    "*Purpose:*\n",
    "Predict the future positions of players over a sequence of frames.\n",
    "\n",
    "*Model details:*\n",
    "\n",
    "Encoder-Decoder LSTM with:\n",
    "\n",
    "- Encoder: processes historical player trajectories.\n",
    "\n",
    "- Decoder: predicts next positions frame by frame.\n",
    "\n",
    "- Linear layer: maps hidden states to (x, y) coordinates.\n",
    "\n",
    "- Handles variable sequence lengths using pack_padded_sequence.\n",
    "\n",
    "- Uses last observed (x, y) as input for next frame prediction.\n",
    "\n",
    "*Why LSTM:*\n",
    "Player trajectories are sequential and time-dependent. LSTMs can capture temporal dependencies better than tree models alone.\n",
    "\n",
    "**4. UTILITY FUNCTIONS**\n",
    "\n",
    "*Purpose:*\n",
    "Handle data preprocessing and batching for models.\n",
    "\n",
    "*Functions include:*\n",
    "\n",
    "- pad_groups(): Pads sequences to maximum length in batch for LSTM.\n",
    "\n",
    "- make_groups_meta(): Organizes player trajectories by nfl_id and generates metadata for reconstructing predictions.\n",
    "\n",
    "- Model loading utilities: load_lstm_model(), load_xgb_model(), load_lgb_model(), load_cat_model().\n",
    "\n",
    "*Why this approach:*\n",
    "\n",
    "Ensures compatibility between variable-length input sequences and fixed-size batch processing in PyTorch.\n",
    "\n",
    "Simplifies model deployment by providing functions to load trained models safely.\n",
    "\n",
    "**5. predict_play() — Multi-frame inference (LSTM + Residual Tree Models)**\n",
    "\n",
    "*Purpose:*\n",
    "Predict player positions over multiple frames using LSTM and optionally refine with tree-based residuals.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Generate features per player and batch into sequences.\n",
    "\n",
    "- Run LSTM to predict (x, y) for T_out frames.\n",
    "\n",
    "*If tree models exist:*\n",
    "\n",
    "- Predict residuals for (x, y) using last input frame features.\n",
    "\n",
    "- Ensemble residuals from XGBoost, LightGBM, and CatBoost using predefined weights.\n",
    "\n",
    "- Apply residuals to LSTM output.\n",
    "\n",
    "- Clip predicted coordinates to field boundaries.\n",
    "\n",
    "*Why this method:*\n",
    "\n",
    "- LSTM captures the sequential patterns in player movement.\n",
    "\n",
    "- Tree models correct small systematic errors (residuals) using learned relationships from historical data.\n",
    "\n",
    "- Ensures physically valid predictions.\n",
    "\n",
    "**6. predict_one_play()**\n",
    "\n",
    "*Purpose:*\n",
    "Simplifies single-play prediction by integrating LSTM and tree model predictions.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Accepts a single play DataFrame.\n",
    "\n",
    "- Calls predict_play() with preloaded models.\n",
    "\n",
    "- Returns the final output in required schema: (game_id, play_id, nfl_id, frame_id, x, y).\n",
    "\n",
    "*Why this method:*\n",
    "Modularizes prediction for single-play use, which is necessary for the Kaggle evaluation loop or local testing.\n",
    "\n",
    "**7. kaggle_main_offline() — Offline Prediction Loop**\n",
    "\n",
    "*Purpose:*\n",
    "Run predictions for the Kaggle Big Data Bowl using local CSV inputs, without requiring the Kaggle-specific nflrush environment.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Loads LSTM and tree-based residual models (XGBoost, LightGBM, CatBoost if available).\n",
    "\n",
    "- Reads the test dataset directly from test_input.csv.\n",
    "\n",
    "- Applies predict_one_play() to generate predicted player positions for all plays.\n",
    "\n",
    "- Fills missing predictions with default values (0.0) to ensure no NaNs in the submission.\n",
    "\n",
    "- Merges predictions with required Kaggle columns (game_id, play_id, nfl_id, frame_id).\n",
    "\n",
    "- Saves the final predictions to a CSV file (submission.csv) for direct Kaggle submission.\n",
    "\n",
    "*Why this method:*\n",
    "\n",
    "- Fully offline and internet-free, compliant with Kaggle submission rules.\n",
    "\n",
    "- Modular, easy to maintain, and flexible for testing with different model combinations.\n",
    "\n",
    "- Avoids dependency on environment-specific packages while ensuring correct submission format.\n",
    "\n",
    "**8. main / Local Testing**\n",
    "\n",
    "*Purpose:*\n",
    "\n",
    "Enable local execution and validation of the full prediction pipeline before submission.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Loads the full test dataset and model artifacts.\n",
    "\n",
    "- Runs predict_one_play() on all test plays.\n",
    "\n",
    "- Generates predictions in the Kaggle-required format.\n",
    "\n",
    "- Saves or previews the output locally for debugging and performance checks.\n",
    "\n",
    "*Why this approach:*\n",
    "\n",
    "- Allows full validation of sequence and residual model predictions offline.\n",
    "\n",
    "- Eliminates the risk of runtime errors due to missing environment-specific packages.\n",
    "\n",
    "- Enables iterative performance tuning and debugging before submission.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- The project combines an LSTM model for sequential player movement prediction with tree-based residual models for accuracy enhancement.\n",
    "\n",
    "- Modular architecture separates data preprocessing, model inference, and submission logic.\n",
    "\n",
    "- Residual models correct errors from the LSTM predictions, improving overall performance.\n",
    "\n",
    "- Local CSV-based workflow ensures safe, flexible, and reproducible testing and submission.\n",
    "\n",
    "This structure is fully compatible with Kaggle Big Data Bowl rules and does not require internet access or nflrush."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a769999",
   "metadata": {
    "papermill": {
     "duration": 0.00338,
     "end_time": "2025-12-01T09:49:39.353593",
     "exception": false,
     "start_time": "2025-12-01T09:49:39.350213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf2bc3de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:49:39.362150Z",
     "iopub.status.busy": "2025-12-01T09:49:39.361696Z",
     "iopub.status.idle": "2025-12-01T09:49:59.073829Z",
     "shell.execute_reply": "2025-12-01T09:49:59.072818Z"
    },
    "papermill": {
     "duration": 19.71878,
     "end_time": "2025-12-01T09:49:59.075758",
     "exception": false,
     "start_time": "2025-12-01T09:49:39.356978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Try to import tree libraries; if missing, we'll skip those models\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    xgb = None\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    import catboost as cb\n",
    "except Exception:\n",
    "    cb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e0bef48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:49:59.085219Z",
     "iopub.status.busy": "2025-12-01T09:49:59.084543Z",
     "iopub.status.idle": "2025-12-01T09:49:59.090917Z",
     "shell.execute_reply": "2025-12-01T09:49:59.089758Z"
    },
    "papermill": {
     "duration": 0.012802,
     "end_time": "2025-12-01T09:49:59.092538",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.079736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "   # CONFIG / PATHS / WEIGHTS\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "LSTM_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_lstm.pth\"\n",
    "XGB_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_xgb.json\"\n",
    "LGB_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_lgb.txt\"\n",
    "CAT_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_cat.cbm\"\n",
    "\n",
    "ENSEMBLE_WEIGHTS = {\"xgb\": 0.3, \"lgb\": 0.3, \"cat\": 0.4}\n",
    "\n",
    "# FIXED: HEIGHT PARSING FUNCTION\n",
    "def to_inches(h):\n",
    "    try:\n",
    "        ft, inch = str(h).split(\"-\")\n",
    "        return int(ft) * 12 + int(inch)\n",
    "    except Exception:\n",
    "        return 72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca363f",
   "metadata": {
    "papermill": {
     "duration": 0.003381,
     "end_time": "2025-12-01T09:49:59.099574",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.096193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. FEATURE ENGINEERING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a40429",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:49:59.108061Z",
     "iopub.status.busy": "2025-12-01T09:49:59.107740Z",
     "iopub.status.idle": "2025-12-01T09:49:59.119165Z",
     "shell.execute_reply": "2025-12-01T09:49:59.118190Z"
    },
    "papermill": {
     "duration": 0.017596,
     "end_time": "2025-12-01T09:49:59.120610",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.103014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in ['x', 'y', 's', 'a', 'o', 'dir']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "\n",
    "    df['height_inches'] = df.get('player_height', '0').apply(to_inches).fillna(72)\n",
    "    df['weight_lbs'] = pd.to_numeric(df.get('player_weight', 200), errors='coerce').fillna(200)\n",
    "\n",
    "    df['bmi'] = (df['weight_lbs'] / (df['height_inches']**2 + 1e-6)) * 703.0\n",
    "\n",
    "    dir_rad = np.radians(pd.to_numeric(df['dir'], errors='coerce').fillna(0.0))\n",
    "    df['heading_x'] = np.sin(dir_rad)\n",
    "    df['heading_y'] = np.cos(dir_rad)\n",
    "\n",
    "    orient_rad = np.radians(pd.to_numeric(df['o'], errors='coerce').fillna(0.0))\n",
    "    df['orient_x'] = np.sin(orient_rad)\n",
    "    df['orient_y'] = np.cos(orient_rad)\n",
    "\n",
    "    dcol = pd.to_numeric(df['dir'], errors='coerce').fillna(0.0)\n",
    "    ocol = pd.to_numeric(df['o'], errors='coerce').fillna(0.0)\n",
    "    diff = np.abs(dcol - ocol)\n",
    "    df['dir_orient_diff'] = np.minimum(diff, 360 - diff)\n",
    "\n",
    "    s = pd.to_numeric(df['s'], errors='coerce').fillna(0.0)\n",
    "    a = pd.to_numeric(df['a'], errors='coerce').fillna(0.0)\n",
    "\n",
    "    df['velocity_x'] = s * df['heading_x']\n",
    "    df['velocity_y'] = s * df['heading_y']\n",
    "    df['acceleration_x'] = a * df['heading_x']\n",
    "    df['acceleration_y'] = a * df['heading_y']\n",
    "\n",
    "    df['speed_squared'] = s**2\n",
    "    df['accel_magnitude'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n",
    "\n",
    "    df['momentum_x'] = df['weight_lbs'] * df['velocity_x']\n",
    "    df['momentum_y'] = df['weight_lbs'] * df['velocity_y']\n",
    "    df['momentum_magnitude'] = np.sqrt(df['momentum_x']**2 + df['momentum_y']**2)\n",
    "\n",
    "    df['kinetic_energy'] = 0.5 * df['weight_lbs'] * df['speed_squared']\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
    "    return df\n",
    "\n",
    "\n",
    "TREE_FEATURE_COLS = [\n",
    "    \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\n",
    "    \"heading_x\",\"heading_y\",\n",
    "    \"velocity_x\",\"velocity_y\",\n",
    "    \"acceleration_x\",\"acceleration_y\",\n",
    "    \"dir_orient_diff\",\n",
    "    \"height_inches\",\"weight_lbs\",\"bmi\",\n",
    "    \"speed_squared\",\"accel_magnitude\",\n",
    "    \"momentum_x\",\"momentum_y\",\"momentum_magnitude\",\"kinetic_energy\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84530921",
   "metadata": {
    "papermill": {
     "duration": 0.003264,
     "end_time": "2025-12-01T09:49:59.127441",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.124177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. MODEL ARCHITECTURE (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4117c8e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:49:59.135820Z",
     "iopub.status.busy": "2025-12-01T09:49:59.135117Z",
     "iopub.status.idle": "2025-12-01T09:49:59.143539Z",
     "shell.execute_reply": "2025-12-01T09:49:59.142635Z"
    },
    "papermill": {
     "duration": 0.014155,
     "end_time": "2025-12-01T09:49:59.144979",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.130824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                               batch_first=True, dropout=dropout)\n",
    "        self.decoder = nn.LSTM(2, hidden_dim, num_layers=num_layers,\n",
    "                               batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, enc_X, enc_lens, T_out=10):\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            enc_X, enc_lens.cpu().numpy(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (h_n, c_n) = self.encoder(packed)\n",
    "\n",
    "        h, c = h_n, c_n\n",
    "        B = enc_X.size(0)\n",
    "\n",
    "        last_xy = []\n",
    "        for i, L in enumerate(enc_lens):\n",
    "            Li = int(L.item())\n",
    "            last_xy.append(enc_X[i, max(0, Li-1), :2])\n",
    "        dec_in = torch.stack(last_xy, dim=0).unsqueeze(1)\n",
    "\n",
    "        preds = []\n",
    "        for t in range(T_out):\n",
    "            out, (h, c) = self.decoder(dec_in, (h, c))\n",
    "            xy = self.fc(out.squeeze(1))\n",
    "            preds.append(xy.unsqueeze(1))\n",
    "            dec_in = xy.unsqueeze(1).detach()\n",
    "\n",
    "        return torch.cat(preds, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be122c0",
   "metadata": {
    "papermill": {
     "duration": 0.003476,
     "end_time": "2025-12-01T09:49:59.152060",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.148584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. UTILITY FUNCTIONS (padding, grouping, loading models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d6c2a7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:49:59.160500Z",
     "iopub.status.busy": "2025-12-01T09:49:59.160186Z",
     "iopub.status.idle": "2025-12-01T09:49:59.171972Z",
     "shell.execute_reply": "2025-12-01T09:49:59.170969Z"
    },
    "papermill": {
     "duration": 0.017976,
     "end_time": "2025-12-01T09:49:59.173532",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.155556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ===========================\n",
    "# GROUP PADDING + META BUILD\n",
    "# ===========================\n",
    "def pad_groups(groups):\n",
    "    B = len(groups)\n",
    "    F = groups[0].shape[1]\n",
    "    T_max = max(g.shape[0] for g in groups)\n",
    "\n",
    "    Xp = np.zeros((B, T_max, F), dtype=np.float32)\n",
    "    lens = np.zeros((B,), dtype=np.int64)\n",
    "\n",
    "    for i, g in enumerate(groups):\n",
    "        T = g.shape[0]\n",
    "        Xp[i, :T, :] = g\n",
    "        lens[i] = T\n",
    "\n",
    "    return torch.tensor(Xp, device=DEVICE), torch.tensor(lens, device=DEVICE)\n",
    "\n",
    "\n",
    "def make_groups_meta(play_df):\n",
    "    df = engineer_features(play_df)\n",
    "    groups, metas = [], []\n",
    "\n",
    "    for nfl_id, g in df.groupby(\"nfl_id\"):\n",
    "        g = g.sort_values(\"frame_id\")\n",
    "        feat = g[[c for c in TREE_FEATURE_COLS]].values.astype(np.float32)\n",
    "\n",
    "        groups.append(feat)\n",
    "        metas.append((\n",
    "            int(g['game_id'].iloc[0]),\n",
    "            int(g['play_id'].iloc[0]),\n",
    "            int(nfl_id),\n",
    "            g['frame_id'].values.astype(int)\n",
    "        ))\n",
    "    return groups, metas\n",
    "\n",
    "\n",
    "# ===========================\n",
    "# MODEL LOADING\n",
    "# ===========================\n",
    "def load_lstm_model(path=LSTM_MODEL_PATH):\n",
    "    model = EncoderDecoderLSTM(input_dim=len(TREE_FEATURE_COLS))\n",
    "    if os.path.exists(path):\n",
    "        state = torch.load(path, map_location=DEVICE)\n",
    "        state = state.get(\"state_dict\", state)\n",
    "        model.load_state_dict(state)\n",
    "    else:\n",
    "        print(\"⚠ LSTM model missing at:\", path)\n",
    "    model.to(DEVICE).eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_xgb_model(path=XGB_MODEL_PATH):\n",
    "    if xgb is None or not os.path.exists(path): return None\n",
    "    try:\n",
    "        booster = xgb.Booster()\n",
    "        booster.load_model(path)\n",
    "        return booster\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_lgb_model(path=LGB_MODEL_PATH):\n",
    "    if lgb is None or not os.path.exists(path): return None\n",
    "    try:\n",
    "        return lgb.Booster(model_file=path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def load_cat_model(path=CAT_MODEL_PATH):\n",
    "    if cb is None or not os.path.exists(path): return None\n",
    "    try:\n",
    "        model = cb.CatBoostRegressor()\n",
    "        model.load_model(path)\n",
    "        return model\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c16813",
   "metadata": {
    "papermill": {
     "duration": 0.003397,
     "end_time": "2025-12-01T09:49:59.180493",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.177096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. predict_play() — Multi-frame inference (LSTM generating absolute preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6bd41f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:49:59.188848Z",
     "iopub.status.busy": "2025-12-01T09:49:59.188538Z",
     "iopub.status.idle": "2025-12-01T09:49:59.201793Z",
     "shell.execute_reply": "2025-12-01T09:49:59.200913Z"
    },
    "papermill": {
     "duration": 0.01964,
     "end_time": "2025-12-01T09:49:59.203560",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.183920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_play(play_input_df, lstm_model, tree_models=None, T_out_default=10):\n",
    "    groups, metas = make_groups_meta(play_input_df)\n",
    "    if len(groups) == 0:\n",
    "        return pd.DataFrame(columns=[\"game_id\",\"play_id\",\"nfl_id\",\"frame_id\",\"x\",\"y\"])\n",
    "\n",
    "    Xt, lens = pad_groups(groups)\n",
    "\n",
    "    T_out = int(play_input_df.get(\"num_frames_output\", pd.Series([T_out_default])).iloc[0])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds_np = lstm_model(Xt, lens, T_out=T_out).cpu().numpy()\n",
    "\n",
    "    rows = []\n",
    "    for i, meta in enumerate(metas):\n",
    "        game_id, play_id, nfl_id, _ = meta\n",
    "        for t in range(preds_np.shape[1]):\n",
    "            rows.append({\n",
    "                \"game_id\": game_id,\n",
    "                \"play_id\": play_id,\n",
    "                \"nfl_id\": nfl_id,\n",
    "                \"frame_id\": t + 1,\n",
    "                \"x\": float(preds_np[i, t, 0]),\n",
    "                \"y\": float(preds_np[i, t, 1]),\n",
    "            })\n",
    "    lstm_out_df = pd.DataFrame(rows)\n",
    "\n",
    "    # No tree models → return LSTM only\n",
    "    if tree_models is None or all(m is None for m in tree_models.values()):\n",
    "        return lstm_out_df\n",
    "\n",
    "    df_input = engineer_features(play_input_df)\n",
    "    last_input_map = {\n",
    "        int(nfl_id): g.sort_values(\"frame_id\").iloc[-1]\n",
    "        for nfl_id, g in df_input.groupby(\"nfl_id\")\n",
    "    }\n",
    "\n",
    "    feat_matrix = []\n",
    "    for _, row in lstm_out_df.iterrows():\n",
    "        base = last_input_map.get(int(row[\"nfl_id\"]))\n",
    "        if base is None:\n",
    "            feat_matrix.append(np.zeros(len(TREE_FEATURE_COLS)))\n",
    "        else:\n",
    "            feat_matrix.append(np.array([base[c] for c in TREE_FEATURE_COLS]))\n",
    "    feat_matrix = np.vstack(feat_matrix)\n",
    "\n",
    "    total_residual = np.zeros((len(lstm_out_df), 2))\n",
    "\n",
    "    for name, model in tree_models.items():\n",
    "        if model is None: continue\n",
    "\n",
    "        try:\n",
    "            if name == 'xgb':\n",
    "                dmat = xgb.DMatrix(feat_matrix)\n",
    "                pred = model.predict(dmat)\n",
    "            else:\n",
    "                pred = model.predict(feat_matrix)\n",
    "\n",
    "            pred = np.array(pred)\n",
    "            if pred.ndim == 1:\n",
    "                pred = np.stack([pred, np.zeros_like(pred)], axis=1)\n",
    "\n",
    "            total_residual += ENSEMBLE_WEIGHTS.get(name, 0) * pred\n",
    "        except Exception as e:\n",
    "            print(f\"Tree model {name} error:\", e)\n",
    "\n",
    "    final_rows = []\n",
    "    for i, row in lstm_out_df.iterrows():\n",
    "        final_rows.append({\n",
    "            \"game_id\": row[\"game_id\"],\n",
    "            \"play_id\": row[\"play_id\"],\n",
    "            \"nfl_id\": row[\"nfl_id\"],\n",
    "            \"frame_id\": row[\"frame_id\"],\n",
    "            \"x\": float(np.clip(row[\"x\"] + total_residual[i, 0], 0, 120)),\n",
    "            \"y\": float(np.clip(row[\"y\"] + total_residual[i, 1], 0, 53.3)),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(final_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43a3c15",
   "metadata": {
    "papermill": {
     "duration": 0.003422,
     "end_time": "2025-12-01T09:49:59.210655",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.207233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. predict_one_play() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a73dfa6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:49:59.218655Z",
     "iopub.status.busy": "2025-12-01T09:49:59.218370Z",
     "iopub.status.idle": "2025-12-01T09:49:59.223573Z",
     "shell.execute_reply": "2025-12-01T09:49:59.222831Z"
    },
    "papermill": {
     "duration": 0.010826,
     "end_time": "2025-12-01T09:49:59.224785",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.213959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_one_play(test_play_df, models):\n",
    "    lstm_model = models[\"lstm\"]\n",
    "    tree_models = {k: models.get(k) for k in [\"xgb\", \"lgb\", \"cat\"]}\n",
    "\n",
    "    pred_df = predict_play(test_play_df, lstm_model, tree_models)\n",
    "    return pred_df[[\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\", \"x\", \"y\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310e77c6",
   "metadata": {
    "papermill": {
     "duration": 0.003477,
     "end_time": "2025-12-01T09:49:59.231967",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.228490",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. kaggle_main() — evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "068b58d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T09:49:59.240716Z",
     "iopub.status.busy": "2025-12-01T09:49:59.239808Z",
     "iopub.status.idle": "2025-12-01T09:50:01.407650Z",
     "shell.execute_reply": "2025-12-01T09:50:01.406480Z"
    },
    "papermill": {
     "duration": 2.173896,
     "end_time": "2025-12-01T09:50:01.409207",
     "exception": false,
     "start_time": "2025-12-01T09:49:59.235311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "⚠ LSTM model missing at: /kaggle/input/nfl-big-data-bowl-2026-prediction/best_lstm.pth\n",
      "Reading test CSV...\n",
      "Running predictions...\n",
      "Saving...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def kaggle_main_offline(test_csv_path, submission_csv_path):\n",
    "    print(\"Loading models...\")\n",
    "\n",
    "    models = {\"lstm\": load_lstm_model(LSTM_MODEL_PATH)}\n",
    "    models[\"xgb\"] = load_xgb_model(XGB_MODEL_PATH)\n",
    "    models[\"lgb\"] = load_lgb_model(LGB_MODEL_PATH)\n",
    "    models[\"cat\"] = load_cat_model(CAT_MODEL_PATH)\n",
    "\n",
    "    print(\"Reading test CSV...\")\n",
    "    test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "    print(\"Running predictions...\")\n",
    "    preds = predict_one_play(test_df, models)\n",
    "\n",
    "    print(\"Saving...\")\n",
    "    preds.to_csv(submission_csv_path, index=False)\n",
    "    print(\"Done!\")\n",
    "    return preds\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kaggle_main_offline(\n",
    "        \"/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\",\n",
    "        \"/kaggle/working/submission.csv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e40122",
   "metadata": {
    "papermill": {
     "duration": 0.003636,
     "end_time": "2025-12-01T09:50:01.416713",
     "exception": false,
     "start_time": "2025-12-01T09:50:01.413077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34.044893,
   "end_time": "2025-12-01T09:50:04.317608",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T09:49:30.272715",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
