{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6753a95a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-01T10:15:12.965185Z",
     "iopub.status.busy": "2025-12-01T10:15:12.964874Z",
     "iopub.status.idle": "2025-12-01T10:15:14.743236Z",
     "shell.execute_reply": "2025-12-01T10:15:14.742098Z"
    },
    "papermill": {
     "duration": 1.785231,
     "end_time": "2025-12-01T10:15:14.744912",
     "exception": false,
     "start_time": "2025-12-01T10:15:12.959681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_inference_server.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_gateway.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w17.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w05.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w10.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w03.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w18.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w05.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w11.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w12.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w16.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w06.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w18.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w10.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w02.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w08.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w12.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w13.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w15.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w03.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w13.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w15.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w16.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w01.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w04.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w14.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w14.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w09.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w01.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w07.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w11.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w06.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w04.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w09.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w17.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w07.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w08.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w02.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e36dae",
   "metadata": {
    "papermill": {
     "duration": 0.003044,
     "end_time": "2025-12-01T10:15:14.751546",
     "exception": false,
     "start_time": "2025-12-01T10:15:14.748502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NFL Big Data Bowl 2026 – Player Movement Prediction Project\n",
    "\n",
    "**1. IMPORTS**\n",
    "\n",
    "*Purpose:*\n",
    "All required Python libraries are imported here, including data manipulation, numerical computation, machine learning frameworks, and deep learning libraries.\n",
    "\n",
    "*Libraries used and reasoning:*\n",
    "\n",
    "- pandas & numpy: Efficient data manipulation and numerical computation.\n",
    "\n",
    "- torch & nn: For building and training the LSTM sequence model.\n",
    "\n",
    "- xgboost, lightgbm, catboost: For tree-based residual models that refine LSTM outputs.\n",
    "\n",
    "- os, glob, pickle: For file handling and model loading.\n",
    "\n",
    "*Why this approach:*\n",
    "Using separate imports and modularizing them makes the code easier to maintain, debug, and ensures all dependencies are listed upfront.\n",
    "\n",
    "**2. FEATURE ENGINEERING FUNCTIONS**\n",
    "\n",
    "*Purpose:*\n",
    "Transform raw player tracking data into meaningful features for model input.\n",
    "\n",
    "*Key logic:*\n",
    "\n",
    "- Input data contains positions, velocities, accelerations, and other metrics per player per frame.\n",
    "\n",
    "- Additional features like relative distance to the line of scrimmage, players’ orientation, and team identifiers were computed.\n",
    "\n",
    "- Feature selection focused on columns used consistently across tree and LSTM models (TREE_FEATURE_COLS).\n",
    "\n",
    "*Why this method:*\n",
    "Proper feature engineering captures the spatial and temporal context for player movement, enabling both LSTM and tree models to make better predictions.\n",
    "\n",
    "**3. MODEL ARCHITECTURE (LSTM)**\n",
    "\n",
    "*Purpose:*\n",
    "Predict the future positions of players over a sequence of frames.\n",
    "\n",
    "*Model details:*\n",
    "\n",
    "Encoder-Decoder LSTM with:\n",
    "\n",
    "- Encoder: processes historical player trajectories.\n",
    "\n",
    "- Decoder: predicts next positions frame by frame.\n",
    "\n",
    "- Linear layer: maps hidden states to (x, y) coordinates.\n",
    "\n",
    "- Handles variable sequence lengths using pack_padded_sequence.\n",
    "\n",
    "- Uses last observed (x, y) as input for next frame prediction.\n",
    "\n",
    "*Why LSTM:*\n",
    "Player trajectories are sequential and time-dependent. LSTMs can capture temporal dependencies better than tree models alone.\n",
    "\n",
    "**4. UTILITY FUNCTIONS**\n",
    "\n",
    "*Purpose:*\n",
    "Handle data preprocessing and batching for models.\n",
    "\n",
    "*Functions include:*\n",
    "\n",
    "- pad_groups(): Pads sequences to maximum length in batch for LSTM.\n",
    "\n",
    "- make_groups_meta(): Organizes player trajectories by nfl_id and generates metadata for reconstructing predictions.\n",
    "\n",
    "- Model loading utilities: load_lstm_model(), load_xgb_model(), load_lgb_model(), load_cat_model().\n",
    "\n",
    "*Why this approach:*\n",
    "\n",
    "Ensures compatibility between variable-length input sequences and fixed-size batch processing in PyTorch.\n",
    "\n",
    "Simplifies model deployment by providing functions to load trained models safely.\n",
    "\n",
    "**5. predict_play() — Multi-frame inference (LSTM + Residual Tree Models)**\n",
    "\n",
    "*Purpose:*\n",
    "Predict player positions over multiple frames using LSTM and optionally refine with tree-based residuals.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Generate features per player and batch into sequences.\n",
    "\n",
    "- Run LSTM to predict (x, y) for T_out frames.\n",
    "\n",
    "*If tree models exist:*\n",
    "\n",
    "- Predict residuals for (x, y) using last input frame features.\n",
    "\n",
    "- Ensemble residuals from XGBoost, LightGBM, and CatBoost using predefined weights.\n",
    "\n",
    "- Apply residuals to LSTM output.\n",
    "\n",
    "- Clip predicted coordinates to field boundaries.\n",
    "\n",
    "*Why this method:*\n",
    "\n",
    "- LSTM captures the sequential patterns in player movement.\n",
    "\n",
    "- Tree models correct small systematic errors (residuals) using learned relationships from historical data.\n",
    "\n",
    "- Ensures physically valid predictions.\n",
    "\n",
    "**6. predict_one_play()**\n",
    "\n",
    "*Purpose:*\n",
    "Simplifies single-play prediction by integrating LSTM and tree model predictions.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Accepts a single play DataFrame.\n",
    "\n",
    "- Calls predict_play() with preloaded models.\n",
    "\n",
    "- Returns the final output in required schema: (game_id, play_id, nfl_id, frame_id, x, y).\n",
    "\n",
    "*Why this method:*\n",
    "Modularizes prediction for single-play use, which is necessary for the Kaggle evaluation loop or local testing.\n",
    "\n",
    "**7. kaggle_main_offline() — Offline Prediction Loop**\n",
    "\n",
    "*Purpose:*\n",
    "Run predictions for the Kaggle Big Data Bowl using local CSV inputs, without requiring the Kaggle-specific nflrush environment.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Loads LSTM and tree-based residual models (XGBoost, LightGBM, CatBoost if available).\n",
    "\n",
    "- Reads the test dataset directly from test_input.csv.\n",
    "\n",
    "- Applies predict_one_play() to generate predicted player positions for all plays.\n",
    "\n",
    "- Fills missing predictions with default values (0.0) to ensure no NaNs in the submission.\n",
    "\n",
    "- Merges predictions with required Kaggle columns (game_id, play_id, nfl_id, frame_id).\n",
    "\n",
    "- Saves the final predictions to a CSV file (submission.csv) for direct Kaggle submission.\n",
    "\n",
    "*Why this method:*\n",
    "\n",
    "- Fully offline and internet-free, compliant with Kaggle submission rules.\n",
    "\n",
    "- Modular, easy to maintain, and flexible for testing with different model combinations.\n",
    "\n",
    "- Avoids dependency on environment-specific packages while ensuring correct submission format.\n",
    "\n",
    "**8. main / Local Testing**\n",
    "\n",
    "*Purpose:*\n",
    "\n",
    "Enable local execution and validation of the full prediction pipeline before submission.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Loads the full test dataset and model artifacts.\n",
    "\n",
    "- Runs predict_one_play() on all test plays.\n",
    "\n",
    "- Generates predictions in the Kaggle-required format.\n",
    "\n",
    "- Saves or previews the output locally for debugging and performance checks.\n",
    "\n",
    "*Why this approach:*\n",
    "\n",
    "- Allows full validation of sequence and residual model predictions offline.\n",
    "\n",
    "- Eliminates the risk of runtime errors due to missing environment-specific packages.\n",
    "\n",
    "- Enables iterative performance tuning and debugging before submission.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- The project combines an LSTM model for sequential player movement prediction with tree-based residual models for accuracy enhancement.\n",
    "\n",
    "- Modular architecture separates data preprocessing, model inference, and submission logic.\n",
    "\n",
    "- Residual models correct errors from the LSTM predictions, improving overall performance.\n",
    "\n",
    "- Local CSV-based workflow ensures safe, flexible, and reproducible testing and submission.\n",
    "\n",
    "This structure is fully compatible with Kaggle Big Data Bowl rules and does not require internet access or nflrush."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551dcdb3",
   "metadata": {
    "papermill": {
     "duration": 0.002999,
     "end_time": "2025-12-01T10:15:14.757640",
     "exception": false,
     "start_time": "2025-12-01T10:15:14.754641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c821e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:15:14.765267Z",
     "iopub.status.busy": "2025-12-01T10:15:14.764840Z",
     "iopub.status.idle": "2025-12-01T10:15:26.044220Z",
     "shell.execute_reply": "2025-12-01T10:15:26.043433Z"
    },
    "papermill": {
     "duration": 11.285379,
     "end_time": "2025-12-01T10:15:26.045991",
     "exception": false,
     "start_time": "2025-12-01T10:15:14.760612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Try to import optional models\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    xgb = None\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    import catboost as cb\n",
    "except Exception:\n",
    "    cb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc2fd87c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:15:26.053911Z",
     "iopub.status.busy": "2025-12-01T10:15:26.053328Z",
     "iopub.status.idle": "2025-12-01T10:15:26.058911Z",
     "shell.execute_reply": "2025-12-01T10:15:26.058277Z"
    },
    "papermill": {
     "duration": 0.010882,
     "end_time": "2025-12-01T10:15:26.060209",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.049327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======================\n",
    "# CONFIG\n",
    "# ======================\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "BASE_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction\"\n",
    "\n",
    "LSTM_MODEL_PATH = f\"{BASE_PATH}/best_lstm.pth\"\n",
    "XGB_MODEL_PATH  = f\"{BASE_PATH}/best_xgb.json\"\n",
    "LGB_MODEL_PATH  = f\"{BASE_PATH}/best_lgb.txt\"\n",
    "CAT_MODEL_PATH  = f\"{BASE_PATH}/best_cat.cbm\"\n",
    "\n",
    "ENSEMBLE_WEIGHTS = {\"xgb\": 0.3, \"lgb\": 0.3, \"cat\": 0.4}\n",
    "\n",
    "\n",
    "# ======================\n",
    "# UTILS\n",
    "# ======================\n",
    "def to_inches(h):\n",
    "    try:\n",
    "        ft, inch = str(h).split(\"-\")\n",
    "        return int(ft) * 12 + int(inch)\n",
    "    except Exception:\n",
    "        return 72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bbcbf4",
   "metadata": {
    "papermill": {
     "duration": 0.003018,
     "end_time": "2025-12-01T10:15:26.066457",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.063439",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. FEATURE ENGINEERING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d9ecb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:15:26.074122Z",
     "iopub.status.busy": "2025-12-01T10:15:26.073515Z",
     "iopub.status.idle": "2025-12-01T10:15:26.083648Z",
     "shell.execute_reply": "2025-12-01T10:15:26.082706Z"
    },
    "papermill": {
     "duration": 0.015492,
     "end_time": "2025-12-01T10:15:26.084934",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.069442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in [\"x\",\"y\",\"s\",\"a\",\"o\",\"dir\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "\n",
    "    df[\"height_inches\"] = df.get(\"player_height\", \"0\").apply(to_inches).fillna(72)\n",
    "    df[\"weight_lbs\"] = pd.to_numeric(df.get(\"player_weight\", 200), errors=\"coerce\").fillna(200)\n",
    "\n",
    "    df[\"bmi\"] = (df[\"weight_lbs\"] / (df[\"height_inches\"]**2 + 1e-6)) * 703\n",
    "\n",
    "    dir_rad = np.radians(pd.to_numeric(df[\"dir\"], errors=\"coerce\").fillna(0))\n",
    "    df[\"heading_x\"] = np.sin(dir_rad)\n",
    "    df[\"heading_y\"] = np.cos(dir_rad)\n",
    "\n",
    "    o_rad = np.radians(pd.to_numeric(df[\"o\"], errors=\"coerce\").fillna(0))\n",
    "    df[\"orient_x\"] = np.sin(o_rad)\n",
    "    df[\"orient_y\"] = np.cos(o_rad)\n",
    "\n",
    "    d = pd.to_numeric(df[\"dir\"], errors=\"coerce\").fillna(0)\n",
    "    o = pd.to_numeric(df[\"o\"], errors=\"coerce\").fillna(0)\n",
    "    diff = np.abs(d - o)\n",
    "    df[\"dir_orient_diff\"] = np.minimum(diff, 360 - diff)\n",
    "\n",
    "    s = pd.to_numeric(df[\"s\"], errors=\"coerce\").fillna(0)\n",
    "    a = pd.to_numeric(df[\"a\"], errors=\"coerce\").fillna(0)\n",
    "\n",
    "    df[\"velocity_x\"] = s * df[\"heading_x\"]\n",
    "    df[\"velocity_y\"] = s * df[\"heading_y\"]\n",
    "    df[\"acceleration_x\"] = a * df[\"heading_x\"]\n",
    "    df[\"acceleration_y\"] = a * df[\"heading_y\"]\n",
    "\n",
    "    df[\"speed_squared\"] = s**2\n",
    "    df[\"accel_magnitude\"] = np.sqrt(df[\"acceleration_x\"]**2 + df[\"acceleration_y\"]**2)\n",
    "\n",
    "    df[\"momentum_x\"] = df[\"weight_lbs\"] * df[\"velocity_x\"]\n",
    "    df[\"momentum_y\"] = df[\"weight_lbs\"] * df[\"velocity_y\"]\n",
    "    df[\"momentum_magnitude\"] = np.sqrt(df[\"momentum_x\"]**2 + df[\"momentum_y\"]**2)\n",
    "\n",
    "    df[\"kinetic_energy\"] = 0.5 * df[\"weight_lbs\"] * df[\"speed_squared\"]\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], 0).fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "TREE_FEATURE_COLS = [\n",
    "    \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\n",
    "    \"heading_x\",\"heading_y\",\n",
    "    \"velocity_x\",\"velocity_y\",\n",
    "    \"acceleration_x\",\"acceleration_y\",\n",
    "    \"dir_orient_diff\",\n",
    "    \"height_inches\",\"weight_lbs\",\"bmi\",\n",
    "    \"speed_squared\",\"accel_magnitude\",\n",
    "    \"momentum_x\",\"momentum_y\",\"momentum_magnitude\",\"kinetic_energy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c15f715",
   "metadata": {
    "papermill": {
     "duration": 0.002973,
     "end_time": "2025-12-01T10:15:26.091111",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.088138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. MODEL ARCHITECTURE (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd28c65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:15:26.098698Z",
     "iopub.status.busy": "2025-12-01T10:15:26.097905Z",
     "iopub.status.idle": "2025-12-01T10:15:26.105244Z",
     "shell.execute_reply": "2025-12-01T10:15:26.104450Z"
    },
    "papermill": {
     "duration": 0.012567,
     "end_time": "2025-12-01T10:15:26.106604",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.094037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.decoder = nn.LSTM(2, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, X, lens, T_out=10):\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            X, lens.cpu().numpy(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (h, c) = self.encoder(packed)\n",
    "\n",
    "        last_xy = []\n",
    "        for i, L in enumerate(lens):\n",
    "            last_xy.append(X[i, max(0, L-1), :2])\n",
    "        dec_in = torch.stack(last_xy, dim=0).unsqueeze(1)\n",
    "\n",
    "        preds = []\n",
    "        for t in range(T_out):\n",
    "            out, (h, c) = self.decoder(dec_in, (h, c))\n",
    "            xy = self.fc(out.squeeze(1))\n",
    "            preds.append(xy.unsqueeze(1))\n",
    "            dec_in = xy.unsqueeze(1).detach()\n",
    "\n",
    "        return torch.cat(preds, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f515a16",
   "metadata": {
    "papermill": {
     "duration": 0.003032,
     "end_time": "2025-12-01T10:15:26.112795",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.109763",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. UTILITY FUNCTIONS (padding, grouping, loading models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ef4bd41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:15:26.120094Z",
     "iopub.status.busy": "2025-12-01T10:15:26.119773Z",
     "iopub.status.idle": "2025-12-01T10:15:26.129655Z",
     "shell.execute_reply": "2025-12-01T10:15:26.128991Z"
    },
    "papermill": {
     "duration": 0.014939,
     "end_time": "2025-12-01T10:15:26.130828",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.115889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_groups(groups):\n",
    "    B = len(groups)\n",
    "    T = max(g.shape[0] for g in groups)\n",
    "    F = groups[0].shape[1]\n",
    "\n",
    "    Xp = np.zeros((B, T, F), np.float32)\n",
    "    lens = np.zeros(B, np.int64)\n",
    "\n",
    "    for i, g in enumerate(groups):\n",
    "        L = g.shape[0]\n",
    "        Xp[i, :L] = g\n",
    "        lens[i] = L\n",
    "\n",
    "    return torch.tensor(Xp, device=DEVICE), torch.tensor(lens, device=DEVICE)\n",
    "\n",
    "\n",
    "def make_groups_meta(df):\n",
    "    df = engineer_features(df)\n",
    "    groups, metas = [], []\n",
    "\n",
    "    for nfl_id, g in df.groupby(\"nfl_id\"):\n",
    "        g = g.sort_values(\"frame_id\")\n",
    "        X = g[TREE_FEATURE_COLS].values.astype(np.float32)\n",
    "        groups.append(X)\n",
    "        metas.append((\n",
    "            int(g[\"game_id\"].iloc[0]),\n",
    "            int(g[\"play_id\"].iloc[0]),\n",
    "            int(nfl_id),\n",
    "            g[\"frame_id\"].values.astype(int)\n",
    "        ))\n",
    "\n",
    "    return groups, metas\n",
    "\n",
    "\n",
    "# ======================\n",
    "# LOAD MODELS\n",
    "# ======================\n",
    "def load_lstm_model():\n",
    "    model = EncoderDecoderLSTM(len(TREE_FEATURE_COLS))\n",
    "    if os.path.exists(LSTM_MODEL_PATH):\n",
    "        state = torch.load(LSTM_MODEL_PATH, map_location=DEVICE)\n",
    "        model.load_state_dict(state.get(\"state_dict\", state))\n",
    "    model.to(DEVICE).eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_xgb():\n",
    "    if xgb is None or not os.path.exists(XGB_MODEL_PATH):\n",
    "        return None\n",
    "    booster = xgb.Booster()\n",
    "    booster.load_model(XGB_MODEL_PATH)\n",
    "    return booster\n",
    "\n",
    "\n",
    "def load_lgb():\n",
    "    if lgb is None or not os.path.exists(LGB_MODEL_PATH):\n",
    "        return None\n",
    "    return lgb.Booster(model_file=LGB_MODEL_PATH)\n",
    "\n",
    "\n",
    "def load_cat():\n",
    "    if cb is None or not os.path.exists(CAT_MODEL_PATH):\n",
    "        return None\n",
    "    model = cb.CatBoostRegressor()\n",
    "    model.load_model(CAT_MODEL_PATH)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018aad42",
   "metadata": {
    "papermill": {
     "duration": 0.002963,
     "end_time": "2025-12-01T10:15:26.136986",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.134023",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. predict_play() — Multi-frame inference (LSTM generating absolute preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d4cd788",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:15:26.144660Z",
     "iopub.status.busy": "2025-12-01T10:15:26.143846Z",
     "iopub.status.idle": "2025-12-01T10:15:26.154801Z",
     "shell.execute_reply": "2025-12-01T10:15:26.154202Z"
    },
    "papermill": {
     "duration": 0.016249,
     "end_time": "2025-12-01T10:15:26.156124",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.139875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_play(play_df, models):\n",
    "    lstm = models[\"lstm\"]\n",
    "    tree_models = {k: models[k] for k in [\"xgb\",\"lgb\",\"cat\"]}\n",
    "\n",
    "    groups, metas = make_groups_meta(play_df)\n",
    "    if len(groups) == 0:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    Xp, lens = pad_groups(groups)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        lstm_out = lstm(Xp, lens, T_out=10).cpu().numpy()\n",
    "\n",
    "    rows = []\n",
    "    for i, meta in enumerate(metas):\n",
    "        game_id, play_id, nfl_id, _ = meta\n",
    "        for t in range(lstm_out.shape[1]):\n",
    "            rows.append({\n",
    "                \"game_id\": game_id,\n",
    "                \"play_id\": play_id,\n",
    "                \"nfl_id\": nfl_id,\n",
    "                \"frame_id\": t+1,\n",
    "                \"x\": float(lstm_out[i,t,0]),\n",
    "                \"y\": float(lstm_out[i,t,1])\n",
    "            })\n",
    "    df_pred = pd.DataFrame(rows)\n",
    "\n",
    "    # If no tree models → return LSTM only\n",
    "    if all(m is None for m in tree_models.values()):\n",
    "        return df_pred\n",
    "\n",
    "    base = engineer_features(play_df)\n",
    "    last_map = {\n",
    "        int(nid): g.sort_values(\"frame_id\").iloc[-1]\n",
    "        for nid, g in base.groupby(\"nfl_id\")\n",
    "    }\n",
    "\n",
    "    feats = []\n",
    "    for _, r in df_pred.iterrows():\n",
    "        b = last_map.get(int(r[\"nfl_id\"]))\n",
    "        if b is None:\n",
    "            feats.append(np.zeros(len(TREE_FEATURE_COLS)))\n",
    "        else:\n",
    "            feats.append([b[c] for c in TREE_FEATURE_COLS])\n",
    "\n",
    "    feats = np.array(feats)\n",
    "\n",
    "    total_res = np.zeros((len(df_pred), 2))\n",
    "\n",
    "    if tree_models[\"xgb\"] is not None:\n",
    "        pred = tree_models[\"xgb\"].predict(xgb.DMatrix(feats))\n",
    "        pred = np.column_stack([pred, np.zeros_like(pred)])\n",
    "        total_res += ENSEMBLE_WEIGHTS[\"xgb\"] * pred\n",
    "\n",
    "    if tree_models[\"lgb\"] is not None:\n",
    "        pred = tree_models[\"lgb\"].predict(feats)\n",
    "        pred = np.column_stack([pred, np.zeros_like(pred)])\n",
    "        total_res += ENSEMBLE_WEIGHTS[\"lgb\"] * pred\n",
    "\n",
    "    if tree_models[\"cat\"] is not None:\n",
    "        pred = tree_models[\"cat\"].predict(feats)\n",
    "        pred = np.column_stack([pred, np.zeros_like(pred)])\n",
    "        total_res += ENSEMBLE_WEIGHTS[\"cat\"] * pred\n",
    "\n",
    "    df_pred[\"x\"] = np.clip(df_pred[\"x\"] + total_res[:,0], 0, 120)\n",
    "    df_pred[\"y\"] = np.clip(df_pred[\"y\"] + total_res[:,1], 0, 53.3)\n",
    "\n",
    "    return df_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816237a0",
   "metadata": {
    "papermill": {
     "duration": 0.003026,
     "end_time": "2025-12-01T10:15:26.162324",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.159298",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. kaggle_main() — evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb2e9a23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T10:15:26.169599Z",
     "iopub.status.busy": "2025-12-01T10:15:26.169313Z",
     "iopub.status.idle": "2025-12-01T10:15:27.870304Z",
     "shell.execute_reply": "2025-12-01T10:15:27.869388Z"
    },
    "papermill": {
     "duration": 1.706435,
     "end_time": "2025-12-01T10:15:27.871769",
     "exception": false,
     "start_time": "2025-12-01T10:15:26.165334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ nflrush not available — skipping competition mode\n",
      "Offline prediction saved → /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "def run_kaggle_server():\n",
    "    try:\n",
    "        import nflrush\n",
    "    except:\n",
    "        print(\"⚠ nflrush not available — skipping competition mode\")\n",
    "        return False\n",
    "\n",
    "    env = nflrush.make_env()\n",
    "    iter_test = env.iter_test()\n",
    "\n",
    "    models = {\n",
    "        \"lstm\": load_lstm_model(),\n",
    "        \"xgb\": load_xgb(),\n",
    "        \"lgb\": load_lgb(),\n",
    "        \"cat\": load_cat()\n",
    "    }\n",
    "\n",
    "    for test_df, sample_prediction_df in iter_test:\n",
    "        pred = predict_play(test_df, models)\n",
    "        submit_df = sample_prediction_df.copy()\n",
    "\n",
    "        # Fill the official submission format\n",
    "        for col in [\"x_position\",\"y_position\"]:\n",
    "            submit_df[col] = 0.\n",
    "\n",
    "        for _, r in pred.iterrows():\n",
    "            submit_df.loc[\n",
    "                (submit_df[\"nfl_id\"] == r[\"nfl_id\"]) &\n",
    "                (submit_df[\"frame_id\"] == r[\"frame_id\"]),\n",
    "                [\"x_position\",\"y_position\"]\n",
    "            ] = [r[\"x\"], r[\"y\"]]\n",
    "\n",
    "        env.predict(submit_df)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# ======================\n",
    "# OFFLINE MODE\n",
    "# ======================\n",
    "def run_offline():\n",
    "    test_path = f\"{BASE_PATH}/test_input.csv\"\n",
    "    out_path  = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "    models = {\n",
    "        \"lstm\": load_lstm_model(),\n",
    "        \"xgb\": load_xgb(),\n",
    "        \"lgb\": load_lgb(),\n",
    "        \"cat\": load_cat()\n",
    "    }\n",
    "\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    pred = predict_play(test_df, models)\n",
    "    pred.to_csv(out_path, index=False)\n",
    "    print(\"Offline prediction saved →\", out_path)\n",
    "\n",
    "\n",
    "# ======================\n",
    "# ENTRY POINT\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    if not run_kaggle_server():   # Try competition server\n",
    "        run_offline()             # Else fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcfe0c0",
   "metadata": {
    "papermill": {
     "duration": 0.003077,
     "end_time": "2025-12-01T10:15:27.878295",
     "exception": false,
     "start_time": "2025-12-01T10:15:27.875218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21.033496,
   "end_time": "2025-12-01T10:15:29.704771",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T10:15:08.671275",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
