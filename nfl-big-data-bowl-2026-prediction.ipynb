{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13a6a5e",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-02T07:57:21.871283Z",
     "iopub.status.busy": "2025-12-02T07:57:21.870987Z",
     "iopub.status.idle": "2025-12-02T07:57:23.675862Z",
     "shell.execute_reply": "2025-12-02T07:57:23.674680Z"
    },
    "papermill": {
     "duration": 1.811827,
     "end_time": "2025-12-02T07:57:23.677426",
     "exception": false,
     "start_time": "2025-12-02T07:57:21.865599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_inference_server.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/nfl_gateway.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/templates.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/base_gateway.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/relay.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/kaggle_evaluation/core/generated/__init__.py\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w17.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w05.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w10.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w03.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w18.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w05.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w11.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w12.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w16.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w06.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w18.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w10.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w02.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w08.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w12.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w13.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w15.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w03.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w13.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w15.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w16.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w01.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w04.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w14.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w14.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w09.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w01.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w07.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w11.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w06.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w04.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w09.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w17.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w07.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/input_2023_w08.csv\n",
      "/kaggle/input/nfl-big-data-bowl-2026-prediction/train/output_2023_w02.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23c4f0",
   "metadata": {
    "papermill": {
     "duration": 0.003295,
     "end_time": "2025-12-02T07:57:23.684566",
     "exception": false,
     "start_time": "2025-12-02T07:57:23.681271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NFL Big Data Bowl 2026 – Player Movement Prediction Project\n",
    "\n",
    "**1. IMPORTS**\n",
    "\n",
    "*Purpose:*\n",
    "All required Python libraries are imported here, including data manipulation, numerical computation, machine learning frameworks, and deep learning libraries.\n",
    "\n",
    "*Libraries used and reasoning:*\n",
    "\n",
    "- pandas & numpy: Efficient data manipulation and numerical computation.\n",
    "\n",
    "- torch & nn: For building and training the LSTM sequence model.\n",
    "\n",
    "- xgboost, lightgbm, catboost: For tree-based residual models that refine LSTM outputs.\n",
    "\n",
    "- os, glob, pickle: For file handling and model loading.\n",
    "\n",
    "*Why this approach:*\n",
    "Using separate imports and modularizing them makes the code easier to maintain, debug, and ensures all dependencies are listed upfront.\n",
    "\n",
    "**2. FEATURE ENGINEERING FUNCTIONS**\n",
    "\n",
    "*Purpose:*\n",
    "Transform raw player tracking data into meaningful features for model input.\n",
    "\n",
    "*Key logic:*\n",
    "\n",
    "- Input data contains positions, velocities, accelerations, and other metrics per player per frame.\n",
    "\n",
    "- Additional features like relative distance to the line of scrimmage, players’ orientation, and team identifiers were computed.\n",
    "\n",
    "- Feature selection focused on columns used consistently across tree and LSTM models (TREE_FEATURE_COLS).\n",
    "\n",
    "*Why this method:*\n",
    "Proper feature engineering captures the spatial and temporal context for player movement, enabling both LSTM and tree models to make better predictions.\n",
    "\n",
    "**3. MODEL ARCHITECTURE (LSTM)**\n",
    "\n",
    "*Purpose:*\n",
    "Predict the future positions of players over a sequence of frames.\n",
    "\n",
    "*Model details:*\n",
    "\n",
    "Encoder-Decoder LSTM with:\n",
    "\n",
    "- Encoder: processes historical player trajectories.\n",
    "\n",
    "- Decoder: predicts next positions frame by frame.\n",
    "\n",
    "- Linear layer: maps hidden states to (x, y) coordinates.\n",
    "\n",
    "- Handles variable sequence lengths using pack_padded_sequence.\n",
    "\n",
    "- Uses last observed (x, y) as input for next frame prediction.\n",
    "\n",
    "*Why LSTM:*\n",
    "Player trajectories are sequential and time-dependent. LSTMs can capture temporal dependencies better than tree models alone.\n",
    "\n",
    "**4. UTILITY FUNCTIONS**\n",
    "\n",
    "*Purpose:*\n",
    "Handle data preprocessing and batching for models.\n",
    "\n",
    "*Functions include:*\n",
    "\n",
    "- pad_groups(): Pads sequences to maximum length in batch for LSTM.\n",
    "\n",
    "- make_groups_meta(): Organizes player trajectories by nfl_id and generates metadata for reconstructing predictions.\n",
    "\n",
    "- Model loading utilities: load_lstm_model(), load_xgb_model(), load_lgb_model(), load_cat_model().\n",
    "\n",
    "*Why this approach:*\n",
    "\n",
    "Ensures compatibility between variable-length input sequences and fixed-size batch processing in PyTorch.\n",
    "\n",
    "Simplifies model deployment by providing functions to load trained models safely.\n",
    "\n",
    "**5. predict_play() — Multi-frame inference (LSTM + Residual Tree Models)**\n",
    "\n",
    "*Purpose:*\n",
    "Predict player positions over multiple frames using LSTM and optionally refine with tree-based residuals.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Generate features per player and batch into sequences.\n",
    "\n",
    "- Run LSTM to predict (x, y) for T_out frames.\n",
    "\n",
    "*If tree models exist:*\n",
    "\n",
    "- Predict residuals for (x, y) using last input frame features.\n",
    "\n",
    "- Ensemble residuals from XGBoost, LightGBM, and CatBoost using predefined weights.\n",
    "\n",
    "- Apply residuals to LSTM output.\n",
    "\n",
    "- Clip predicted coordinates to field boundaries.\n",
    "\n",
    "*Why this method:*\n",
    "\n",
    "- LSTM captures the sequential patterns in player movement.\n",
    "\n",
    "- Tree models correct small systematic errors (residuals) using learned relationships from historical data.\n",
    "\n",
    "- Ensures physically valid predictions.\n",
    "\n",
    "**6. predict_one_play()**\n",
    "\n",
    "*Purpose:*\n",
    "Simplifies single-play prediction by integrating LSTM and tree model predictions.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Accepts a single play DataFrame.\n",
    "\n",
    "- Calls predict_play() with preloaded models.\n",
    "\n",
    "- Returns the final output in required schema: (game_id, play_id, nfl_id, frame_id, x, y).\n",
    "\n",
    "*Why this method:*\n",
    "Modularizes prediction for single-play use, which is necessary for the Kaggle evaluation loop or local testing.\n",
    "\n",
    "**7. kaggle_main_offline() — Offline Prediction Loop**\n",
    "\n",
    "*Purpose:*\n",
    "Run predictions for the Kaggle Big Data Bowl using local CSV inputs, without requiring the Kaggle-specific nflrush environment.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Loads LSTM and tree-based residual models (XGBoost, LightGBM, CatBoost if available).\n",
    "\n",
    "- Reads the test dataset directly from test_input.csv.\n",
    "\n",
    "- Applies predict_one_play() to generate predicted player positions for all plays.\n",
    "\n",
    "- Fills missing predictions with default values (0.0) to ensure no NaNs in the submission.\n",
    "\n",
    "- Merges predictions with required Kaggle columns (game_id, play_id, nfl_id, frame_id).\n",
    "\n",
    "- Saves the final predictions to a CSV file (submission.csv) for direct Kaggle submission.\n",
    "\n",
    "*Why this method:*\n",
    "\n",
    "- Fully offline and internet-free, compliant with Kaggle submission rules.\n",
    "\n",
    "- Modular, easy to maintain, and flexible for testing with different model combinations.\n",
    "\n",
    "- Avoids dependency on environment-specific packages while ensuring correct submission format.\n",
    "\n",
    "**8. main / Local Testing**\n",
    "\n",
    "*Purpose:*\n",
    "\n",
    "Enable local execution and validation of the full prediction pipeline before submission.\n",
    "\n",
    "*Logic:*\n",
    "\n",
    "- Loads the full test dataset and model artifacts.\n",
    "\n",
    "- Runs predict_one_play() on all test plays.\n",
    "\n",
    "- Generates predictions in the Kaggle-required format.\n",
    "\n",
    "- Saves or previews the output locally for debugging and performance checks.\n",
    "\n",
    "*Why this approach:*\n",
    "\n",
    "- Allows full validation of sequence and residual model predictions offline.\n",
    "\n",
    "- Eliminates the risk of runtime errors due to missing environment-specific packages.\n",
    "\n",
    "- Enables iterative performance tuning and debugging before submission.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "- The project combines an LSTM model for sequential player movement prediction with tree-based residual models for accuracy enhancement.\n",
    "\n",
    "- Modular architecture separates data preprocessing, model inference, and submission logic.\n",
    "\n",
    "- Residual models correct errors from the LSTM predictions, improving overall performance.\n",
    "\n",
    "- Local CSV-based workflow ensures safe, flexible, and reproducible testing and submission.\n",
    "\n",
    "This structure is fully compatible with Kaggle Big Data Bowl rules and does not require internet access or nflrush."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c55e73c",
   "metadata": {
    "papermill": {
     "duration": 0.003218,
     "end_time": "2025-12-02T07:57:23.691135",
     "exception": false,
     "start_time": "2025-12-02T07:57:23.687917",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56171a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T07:57:23.699028Z",
     "iopub.status.busy": "2025-12-02T07:57:23.698646Z",
     "iopub.status.idle": "2025-12-02T07:57:35.955753Z",
     "shell.execute_reply": "2025-12-02T07:57:35.954787Z"
    },
    "papermill": {
     "duration": 12.262825,
     "end_time": "2025-12-02T07:57:35.957218",
     "exception": false,
     "start_time": "2025-12-02T07:57:23.694393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Try to import tree libraries; if missing, we'll skip those models\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    xgb = None\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception:\n",
    "    lgb = None\n",
    "\n",
    "try:\n",
    "    import catboost as cb\n",
    "except Exception:\n",
    "    cb = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fd6279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T07:57:35.966429Z",
     "iopub.status.busy": "2025-12-02T07:57:35.965252Z",
     "iopub.status.idle": "2025-12-02T07:57:35.970689Z",
     "shell.execute_reply": "2025-12-02T07:57:35.969836Z"
    },
    "papermill": {
     "duration": 0.011481,
     "end_time": "2025-12-02T07:57:35.972310",
     "exception": false,
     "start_time": "2025-12-02T07:57:35.960829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "LSTM_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_lstm.pth\"\n",
    "XGB_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_xgb.json\"\n",
    "LGB_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_lgb.txt\"\n",
    "CAT_MODEL_PATH = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/best_cat.cbm\"\n",
    "\n",
    "# Ensemble blending weights for residuals (sum <= 1)\n",
    "ENSEMBLE_WEIGHTS = {\"xgb\": 0.3, \"lgb\": 0.3, \"cat\": 0.4}\n",
    "\n",
    "# Field bounds\n",
    "FIELD_X_MAX = 120.0\n",
    "FIELD_Y_MAX = 53.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b24803",
   "metadata": {
    "papermill": {
     "duration": 0.003228,
     "end_time": "2025-12-02T07:57:35.979046",
     "exception": false,
     "start_time": "2025-12-02T07:57:35.975818",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. FEATURE ENGINEERING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033ff8b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T07:57:35.987042Z",
     "iopub.status.busy": "2025-12-02T07:57:35.986782Z",
     "iopub.status.idle": "2025-12-02T07:57:35.999103Z",
     "shell.execute_reply": "2025-12-02T07:57:35.998081Z"
    },
    "papermill": {
     "duration": 0.018372,
     "end_time": "2025-12-02T07:57:36.000866",
     "exception": false,
     "start_time": "2025-12-02T07:57:35.982494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_inches(h):\n",
    "    # safe parser: if h is missing, treat as 72\"\n",
    "    try:\n",
    "        if pd.isna(h):\n",
    "            return 72\n",
    "        s = str(h)\n",
    "        if \"-\" in s:\n",
    "            ft, inch = s.split(\"-\")\n",
    "            return int(ft) * 12 + int(inch)\n",
    "        # sometimes given already in inches\n",
    "        return int(float(s))\n",
    "    except Exception:\n",
    "        return 72\n",
    "\n",
    "def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # ensure numeric columns exist\n",
    "    for col in ['x', 'y', 's', 'a', 'o', 'dir']:\n",
    "        if col not in df.columns:\n",
    "            df[col] = 0.0\n",
    "\n",
    "    # safe player_height / weight handling\n",
    "    if 'player_height' in df.columns:\n",
    "        df['height_inches'] = df['player_height'].fillna(\"0\").apply(to_inches)\n",
    "    else:\n",
    "        df['height_inches'] = 72\n",
    "\n",
    "    if 'player_weight' in df.columns:\n",
    "        df['weight_lbs'] = pd.to_numeric(df['player_weight'], errors='coerce').fillna(200)\n",
    "    else:\n",
    "        df['weight_lbs'] = 200\n",
    "\n",
    "    df['bmi'] = (df['weight_lbs'] / (df['height_inches']**2 + 1e-6)) * 703.0\n",
    "\n",
    "    dir_rad = np.radians(pd.to_numeric(df['dir'], errors='coerce').fillna(0.0))\n",
    "    df['heading_x'] = np.sin(dir_rad)\n",
    "    df['heading_y'] = np.cos(dir_rad)\n",
    "\n",
    "    orient_rad = np.radians(pd.to_numeric(df['o'], errors='coerce').fillna(0.0))\n",
    "    df['orient_x'] = np.sin(orient_rad)\n",
    "    df['orient_y'] = np.cos(orient_rad)\n",
    "\n",
    "    dcol = pd.to_numeric(df['dir'], errors='coerce').fillna(0.0)\n",
    "    ocol = pd.to_numeric(df['o'], errors='coerce').fillna(0.0)\n",
    "    diff = np.abs(dcol - ocol)\n",
    "    df['dir_orient_diff'] = np.minimum(diff, 360 - diff)\n",
    "\n",
    "    s = pd.to_numeric(df['s'], errors='coerce').fillna(0.0)\n",
    "    a = pd.to_numeric(df['a'], errors='coerce').fillna(0.0)\n",
    "\n",
    "    df['velocity_x'] = s * df['heading_x']\n",
    "    df['velocity_y'] = s * df['heading_y']\n",
    "    df['acceleration_x'] = a * df['heading_x']\n",
    "    df['acceleration_y'] = a * df['heading_y']\n",
    "\n",
    "    df['speed_squared'] = s**2\n",
    "    df['accel_magnitude'] = np.sqrt(df['acceleration_x']**2 + df['acceleration_y']**2)\n",
    "\n",
    "    df['momentum_x'] = df['weight_lbs'] * df['velocity_x']\n",
    "    df['momentum_y'] = df['weight_lbs'] * df['velocity_y']\n",
    "    df['momentum_magnitude'] = np.sqrt(df['momentum_x']**2 + df['momentum_y']**2)\n",
    "\n",
    "    df['kinetic_energy'] = 0.5 * df['weight_lbs'] * df['speed_squared']\n",
    "\n",
    "    df = df.replace([np.inf, -np.inf], 0.0).fillna(0.0)\n",
    "    return df\n",
    "\n",
    "TREE_FEATURE_COLS = [\n",
    "    \"x\",\"y\",\"s\",\"a\",\"o\",\"dir\",\n",
    "    \"heading_x\",\"heading_y\",\n",
    "    \"velocity_x\",\"velocity_y\",\n",
    "    \"acceleration_x\",\"acceleration_y\",\n",
    "    \"dir_orient_diff\",\n",
    "    \"height_inches\",\"weight_lbs\",\"bmi\",\n",
    "    \"speed_squared\",\"accel_magnitude\",\n",
    "    \"momentum_x\",\"momentum_y\",\"momentum_magnitude\",\"kinetic_energy\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6948de8f",
   "metadata": {
    "papermill": {
     "duration": 0.003226,
     "end_time": "2025-12-02T07:57:36.007513",
     "exception": false,
     "start_time": "2025-12-02T07:57:36.004287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. MODEL ARCHITECTURE (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e8a7b21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T07:57:36.015574Z",
     "iopub.status.busy": "2025-12-02T07:57:36.015305Z",
     "iopub.status.idle": "2025-12-02T07:57:36.024078Z",
     "shell.execute_reply": "2025-12-02T07:57:36.023018Z"
    },
    "papermill": {
     "duration": 0.014567,
     "end_time": "2025-12-02T07:57:36.025542",
     "exception": false,
     "start_time": "2025-12-02T07:57:36.010975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_layers=2, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                               batch_first=True, dropout=dropout)\n",
    "        self.decoder = nn.LSTM(2, hidden_dim, num_layers=num_layers,\n",
    "                               batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 2)\n",
    "\n",
    "    def forward(self, enc_X, enc_lens, T_out=10):\n",
    "        # enc_X: (B, T, F)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(enc_X, enc_lens.cpu().numpy(),\n",
    "                                                   batch_first=True, enforce_sorted=False)\n",
    "        _, (h_n, c_n) = self.encoder(packed)\n",
    "        h, c = h_n, c_n\n",
    "\n",
    "        # build decoder initial input = last observed x,y per sequence\n",
    "        last_xy = []\n",
    "        for i, L in enumerate(enc_lens):\n",
    "            Li = int(L.item())\n",
    "            last_xy.append(enc_X[i, max(0, Li-1), :2])\n",
    "        dec_in = torch.stack(last_xy, dim=0).unsqueeze(1)  # (B,1,2)\n",
    "\n",
    "        preds = []\n",
    "        for t in range(T_out):\n",
    "            out, (h, c) = self.decoder(dec_in, (h, c))\n",
    "            xy = self.fc(out.squeeze(1))\n",
    "            preds.append(xy.unsqueeze(1))\n",
    "            dec_in = xy.unsqueeze(1).detach()\n",
    "\n",
    "        return torch.cat(preds, dim=1)  # (B, T_out, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd60cf31",
   "metadata": {
    "papermill": {
     "duration": 0.003988,
     "end_time": "2025-12-02T07:57:36.033409",
     "exception": false,
     "start_time": "2025-12-02T07:57:36.029421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. UTILITY FUNCTIONS (padding, grouping, loading models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "291f453f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T07:57:36.041908Z",
     "iopub.status.busy": "2025-12-02T07:57:36.041592Z",
     "iopub.status.idle": "2025-12-02T07:57:36.053956Z",
     "shell.execute_reply": "2025-12-02T07:57:36.052952Z"
    },
    "papermill": {
     "duration": 0.018894,
     "end_time": "2025-12-02T07:57:36.055724",
     "exception": false,
     "start_time": "2025-12-02T07:57:36.036830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Utils: grouping / padding\n",
    "# ---------------------\n",
    "def pad_groups(groups):\n",
    "    B = len(groups)\n",
    "    F = groups[0].shape[1]\n",
    "    T_max = max(g.shape[0] for g in groups)\n",
    "    Xp = np.zeros((B, T_max, F), dtype=np.float32)\n",
    "    lens = np.zeros((B,), dtype=np.int64)\n",
    "    for i, g in enumerate(groups):\n",
    "        T = g.shape[0]\n",
    "        Xp[i, :T, :] = g\n",
    "        lens[i] = T\n",
    "    return torch.tensor(Xp, dtype=torch.float32, device=DEVICE), torch.tensor(lens, dtype=torch.int64, device=DEVICE)\n",
    "\n",
    "def make_groups_meta(play_df):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      groups: list of (T_obs, F) arrays per player\n",
    "      metas: list of dicts per player: {game_id, play_id, nfl_id, observed_frame_ids}\n",
    "    \"\"\"\n",
    "    df = engineer_features(play_df.copy())\n",
    "    groups = []\n",
    "    metas = []\n",
    "    for nfl_id, g in df.groupby(\"nfl_id\"):\n",
    "        g = g.sort_values(\"frame_id\")\n",
    "        feat = g[[c for c in TREE_FEATURE_COLS if c in g.columns]].values.astype(np.float32)\n",
    "        groups.append(feat)\n",
    "        metas.append({\n",
    "            \"game_id\": int(g['game_id'].iloc[0]),\n",
    "            \"play_id\": int(g['play_id'].iloc[0]),\n",
    "            \"nfl_id\": int(nfl_id),\n",
    "            \"observed_frame_ids\": g['frame_id'].values.astype(int)\n",
    "        })\n",
    "    return groups, metas\n",
    "\n",
    "# ---------------------\n",
    "# Model loaders\n",
    "# ---------------------\n",
    "def load_lstm_model(path=LSTM_MODEL_PATH):\n",
    "    model = EncoderDecoderLSTM(input_dim=len(TREE_FEATURE_COLS))\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            state = torch.load(path, map_location=DEVICE)\n",
    "            if isinstance(state, dict) and 'state_dict' in state:\n",
    "                state = state['state_dict']\n",
    "            model.load_state_dict(state)\n",
    "            print(\"✔ LSTM model loaded from\", path)\n",
    "        except Exception as e:\n",
    "            print(\"⚠ Failed to load LSTM state_dict:\", e)\n",
    "            # return model uninitialized (will still run)\n",
    "    else:\n",
    "        print(\"⚠ LSTM model missing at:\", path)\n",
    "    model.to(DEVICE).eval()\n",
    "    return model\n",
    "\n",
    "def load_xgb_model(path=XGB_MODEL_PATH):\n",
    "    if xgb is None or not os.path.exists(path):\n",
    "        return None\n",
    "    try:\n",
    "        booster = xgb.Booster()\n",
    "        booster.load_model(path)\n",
    "        return booster\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def load_lgb_model(path=LGB_MODEL_PATH):\n",
    "    if lgb is None or not os.path.exists(path):\n",
    "        return None\n",
    "    try:\n",
    "        return lgb.Booster(model_file=path)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def load_cat_model(path=CAT_MODEL_PATH):\n",
    "    if cb is None or not os.path.exists(path):\n",
    "        return None\n",
    "    try:\n",
    "        model = cb.CatBoostRegressor()\n",
    "        model.load_model(path)\n",
    "        return model\n",
    "    except Exception:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62316d0a",
   "metadata": {
    "papermill": {
     "duration": 0.003276,
     "end_time": "2025-12-02T07:57:36.062969",
     "exception": false,
     "start_time": "2025-12-02T07:57:36.059693",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. predict_play() — Multi-frame inference (LSTM generating absolute preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95344a72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T07:57:36.071484Z",
     "iopub.status.busy": "2025-12-02T07:57:36.071131Z",
     "iopub.status.idle": "2025-12-02T07:57:36.084904Z",
     "shell.execute_reply": "2025-12-02T07:57:36.083844Z"
    },
    "papermill": {
     "duration": 0.019945,
     "end_time": "2025-12-02T07:57:36.086425",
     "exception": false,
     "start_time": "2025-12-02T07:57:36.066480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_play_array(play_input_df, lstm_model, tree_models=None, T_out_default=10):\n",
    "    \"\"\"\n",
    "    Predicts sequences for all players in play_input_df.\n",
    "    Returns dict keyed by (game_id, play_id, nfl_id) -> np.array shape (T_out, 2)\n",
    "    \"\"\"\n",
    "    groups, metas = make_groups_meta(play_input_df)\n",
    "    if len(groups) == 0:\n",
    "        return {}\n",
    "\n",
    "    Xt, lens = pad_groups(groups)\n",
    "    # determine T_out (if play provides num_frames_output)\n",
    "    try:\n",
    "        T_out = int(play_input_df.get(\"num_frames_output\", pd.Series([T_out_default])).iloc[0])\n",
    "        if T_out <= 0:\n",
    "            T_out = T_out_default\n",
    "    except Exception:\n",
    "        T_out = T_out_default\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = lstm_model(Xt, lens, T_out=T_out)  # (B, T_out, 2)\n",
    "        preds_np = preds.cpu().numpy()\n",
    "\n",
    "    # build map\n",
    "    preds_map = {}\n",
    "    for i, meta in enumerate(metas):\n",
    "        key = (meta[\"game_id\"], meta[\"play_id\"], meta[\"nfl_id\"])\n",
    "        preds_map[key] = preds_np[i]  # shape (T_out, 2)\n",
    "\n",
    "    # If no tree models, return early\n",
    "    if tree_models is None or all(m is None for m in tree_models.values()):\n",
    "        return preds_map\n",
    "\n",
    "    # otherwise compute residuals per predicted row (use last observed features)\n",
    "    df_input = engineer_features(play_input_df.copy())\n",
    "    last_input_map = {\n",
    "        int(nfl_id): g.sort_values(\"frame_id\").iloc[-1]\n",
    "        for nfl_id, g in df_input.groupby(\"nfl_id\")\n",
    "    }\n",
    "\n",
    "    # Build feature matrix repeating last_input per predicted frame index\n",
    "    feat_rows = []\n",
    "    keys = []\n",
    "    for key, arr in preds_map.items():\n",
    "        gid, pid, nid = key\n",
    "        for t in range(arr.shape[0]):\n",
    "            base = last_input_map.get(int(nid))\n",
    "            if base is None:\n",
    "                feat_rows.append(np.zeros(len(TREE_FEATURE_COLS), dtype=np.float32))\n",
    "            else:\n",
    "                feat_rows.append(np.array([base[c] if c in base.index else 0.0 for c in TREE_FEATURE_COLS], dtype=np.float32))\n",
    "            keys.append(key)\n",
    "    if len(feat_rows) == 0:\n",
    "        return preds_map\n",
    "\n",
    "    feat_matrix = np.vstack(feat_rows)  # (N_rows_total, n_feats)\n",
    "    total_residual = np.zeros((feat_matrix.shape[0], 2), dtype=np.float32)\n",
    "\n",
    "    # predict residuals by model\n",
    "    row_idx = 0\n",
    "    for model_name in ['xgb', 'lgb', 'cat']:\n",
    "        m = tree_models.get(model_name)\n",
    "        if m is None:\n",
    "            continue\n",
    "        try:\n",
    "            if model_name == 'xgb' and isinstance(m, xgb.Booster):\n",
    "                dmat = xgb.DMatrix(feat_matrix, feature_names=TREE_FEATURE_COLS)\n",
    "                pred_flat = m.predict(dmat)\n",
    "            else:\n",
    "                pred_flat = m.predict(feat_matrix)\n",
    "            pred_flat = np.asarray(pred_flat)\n",
    "            if pred_flat.ndim == 1:\n",
    "                dx = pred_flat\n",
    "                dy = np.zeros_like(dx)\n",
    "                preds_model = np.vstack([dx, dy]).T\n",
    "            else:\n",
    "                preds_model = pred_flat.reshape(-1, 2)\n",
    "            total_residual += ENSEMBLE_WEIGHTS.get(model_name, 0.0) * preds_model\n",
    "        except Exception as e:\n",
    "            print(f\"Tree model {model_name} prediction failed: {e}\")\n",
    "\n",
    "    # apply residuals back into preds_map\n",
    "    # feats were arranged as contiguous blocks per key in keys list: we iterate and add residuals sequentially\n",
    "    idx = 0\n",
    "    for key in preds_map.keys():\n",
    "        arr = preds_map[key]  # (T_out, 2)\n",
    "        T = arr.shape[0]\n",
    "        if T == 0:\n",
    "            continue\n",
    "        res_block = total_residual[idx: idx+T] if idx+T <= total_residual.shape[0] else np.zeros((T,2))\n",
    "        preds_map[key] = arr + res_block\n",
    "        idx += T\n",
    "\n",
    "    return preds_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db10f6b1",
   "metadata": {
    "papermill": {
     "duration": 0.003159,
     "end_time": "2025-12-02T07:57:36.093004",
     "exception": false,
     "start_time": "2025-12-02T07:57:36.089845",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. kaggle_main() — evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4261f9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T07:57:36.101221Z",
     "iopub.status.busy": "2025-12-02T07:57:36.100262Z",
     "iopub.status.idle": "2025-12-02T07:57:36.110455Z",
     "shell.execute_reply": "2025-12-02T07:57:36.109478Z"
    },
    "papermill": {
     "duration": 0.016031,
     "end_time": "2025-12-02T07:57:36.112122",
     "exception": false,
     "start_time": "2025-12-02T07:57:36.096091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assemble_predictions_for_sample(sample_df, preds_map):\n",
    "    \"\"\"\n",
    "    sample_df: DataFrame with columns ['game_id','play_id','nfl_id','frame_id', ...]\n",
    "    preds_map: dict (game,play,nfl) -> np.array (T_out,2)\n",
    "    We assume sample_df rows for a given player are ordered by frame_id asc\n",
    "    and correspond to predicted time steps t=0,1,... for that player.\n",
    "    \"\"\"\n",
    "    out_rows = []\n",
    "    # group sample rows by player\n",
    "    grouped = sample_df.groupby(['game_id','play_id','nfl_id'], sort=False)\n",
    "    for (gid, pid, nid), group in grouped:\n",
    "        key = (int(gid), int(pid), int(nid))\n",
    "        preds_arr = preds_map.get(key)  # shape (T_out,2) or None\n",
    "        # if preds_arr is None, we'll fill zeros\n",
    "        if preds_arr is None:\n",
    "            # fill zeros for all rows\n",
    "            for _, r in group.iterrows():\n",
    "                out_rows.append({\n",
    "                    \"game_id\": int(r['game_id']),\n",
    "                    \"play_id\": int(r['play_id']),\n",
    "                    \"nfl_id\": int(r['nfl_id']),\n",
    "                    \"frame_id\": int(r['frame_id']),\n",
    "                    \"x\": 0.0,\n",
    "                    \"y\": 0.0\n",
    "                })\n",
    "            continue\n",
    "\n",
    "        # ensure group is sorted by frame_id ascending (Kaggle expects this)\n",
    "        group_sorted = group.sort_values(\"frame_id\")\n",
    "        for t_idx, (_, r) in enumerate(group_sorted.iterrows()):\n",
    "            tt = min(t_idx, preds_arr.shape[0]-1)  # if sample requests more frames than predicted, reuse last\n",
    "            x_pred = float(np.clip(preds_arr[tt,0], 0.0, FIELD_X_MAX))\n",
    "            y_pred = float(np.clip(preds_arr[tt,1], 0.0, FIELD_Y_MAX))\n",
    "            out_rows.append({\n",
    "                \"game_id\": int(r['game_id']),\n",
    "                \"play_id\": int(r['play_id']),\n",
    "                \"nfl_id\": int(r['nfl_id']),\n",
    "                \"frame_id\": int(r['frame_id']),\n",
    "                \"x\": x_pred,\n",
    "                \"y\": y_pred\n",
    "            })\n",
    "    out_df = pd.DataFrame(out_rows)\n",
    "    # Keep original sample order\n",
    "    merged = sample_df.merge(out_df, on=['game_id','play_id','nfl_id','frame_id'], how='left', sort=False)\n",
    "    # If any left NaNs (shouldn't), fill zeros\n",
    "    merged['x'] = merged['x'].fillna(0.0)\n",
    "    merged['y'] = merged['y'].fillna(0.0)\n",
    "    return merged[['game_id','play_id','nfl_id','frame_id','x','y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c82f1734",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T07:57:36.120570Z",
     "iopub.status.busy": "2025-12-02T07:57:36.120282Z",
     "iopub.status.idle": "2025-12-02T07:57:36.128633Z",
     "shell.execute_reply": "2025-12-02T07:57:36.127737Z"
    },
    "papermill": {
     "duration": 0.014362,
     "end_time": "2025-12-02T07:57:36.130148",
     "exception": false,
     "start_time": "2025-12-02T07:57:36.115786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def offline_predict_and_save(test_input_path, sample_path, submission_path):\n",
    "    \"\"\"\n",
    "    Offline pipeline:\n",
    "      - test_input_path : path to test_input.csv (historical frames)\n",
    "      - sample_path     : path to test.csv (rows Kaggle expects predictions for)\n",
    "      - submission_path : path to write submission.csv\n",
    "    \"\"\"\n",
    "    print(\"Loading models...\")\n",
    "    models = {\n",
    "        \"lstm\": load_lstm_model(LSTM_MODEL_PATH),\n",
    "        \"xgb\": load_xgb_model(XGB_MODEL_PATH),\n",
    "        \"lgb\": load_lgb_model(LGB_MODEL_PATH),\n",
    "        \"cat\": load_cat_model(CAT_MODEL_PATH)\n",
    "    }\n",
    "\n",
    "    print(\"Reading test input (history)...\")\n",
    "    test_input = pd.read_csv(test_input_path)\n",
    "    print(f\"  rows: {len(test_input)}\")\n",
    "\n",
    "    print(\"Reading sample (expected prediction rows)...\")\n",
    "    sample = pd.read_csv(sample_path)\n",
    "    print(f\"  rows: {len(sample)}\")\n",
    "\n",
    "    # We'll run per play (group by game_id, play_id) to limit memory and to pass each play separately.\n",
    "    preds_map_global = {}\n",
    "\n",
    "    plays = test_input.groupby(['game_id','play_id'])\n",
    "    total_plays = len(list(plays.groups.keys()))\n",
    "    print(f\"Predicting for {total_plays} plays...\")\n",
    "\n",
    "    # For speed we iterate groupby directly\n",
    "    for (gid, pid), play_df in plays:\n",
    "        try:\n",
    "            # predict arrays for this play\n",
    "            preds_map = predict_play_array(play_df, models['lstm'], tree_models={'xgb':models['xgb'],'lgb':models['lgb'],'cat':models['cat']})\n",
    "            # merge into global dict\n",
    "            preds_map_global.update(preds_map)\n",
    "        except Exception as e:\n",
    "            # on failure, skip play (preds_map_global remains without these keys; assemble step will fill zeros)\n",
    "            print(f\"Warning: prediction failed for play {(gid,pid)}: {e}\")\n",
    "            continue\n",
    "\n",
    "    print(\"Assembling final submission aligned to sample rows...\")\n",
    "    submission_df = assemble_predictions_for_sample(sample, preds_map_global)\n",
    "\n",
    "    # Final check for NaNs\n",
    "    if submission_df[['x','y']].isna().any().any():\n",
    "        print(\"Warning: NaNs still present in final submission — filling zeros.\")\n",
    "        submission_df['x'] = submission_df['x'].fillna(0.0)\n",
    "        submission_df['y'] = submission_df['y'].fillna(0.0)\n",
    "\n",
    "    print(\"Saving submission to\", submission_path)\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(\"Saved. Rows:\", len(submission_df))\n",
    "    return submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5515e97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-02T07:57:36.138637Z",
     "iopub.status.busy": "2025-12-02T07:57:36.137990Z",
     "iopub.status.idle": "2025-12-02T07:57:42.187904Z",
     "shell.execute_reply": "2025-12-02T07:57:42.186688Z"
    },
    "papermill": {
     "duration": 6.055923,
     "end_time": "2025-12-02T07:57:42.189520",
     "exception": false,
     "start_time": "2025-12-02T07:57:36.133597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models...\n",
      "⚠ LSTM model missing at: /kaggle/input/nfl-big-data-bowl-2026-prediction/best_lstm.pth\n",
      "Reading test input (history)...\n",
      "  rows: 49753\n",
      "Reading sample (expected prediction rows)...\n",
      "  rows: 5837\n",
      "Predicting for 143 plays...\n",
      "Assembling final submission aligned to sample rows...\n",
      "Saving submission to /kaggle/working/submission.csv\n",
      "Saved. Rows: 5837\n",
      "Done. Submission ready at: /kaggle/working/submission.csv\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Paths inside Kaggle environment\n",
    "    test_input_path = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/test_input.csv\"\n",
    "    sample_path = \"/kaggle/input/nfl-big-data-bowl-2026-prediction/test.csv\"  # sample rows to fill\n",
    "    submission_path = \"/kaggle/working/submission.csv\"\n",
    "\n",
    "    # Sanity check files exist\n",
    "    for p in [test_input_path, sample_path]:\n",
    "        if not os.path.exists(p):\n",
    "            print(f\"ERROR: required file missing: {p}\")\n",
    "            sys.exit(1)\n",
    "\n",
    "    submission = offline_predict_and_save(test_input_path, sample_path, submission_path)\n",
    "    print(\"Done. Submission ready at:\", submission_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee16780",
   "metadata": {
    "papermill": {
     "duration": 0.003463,
     "end_time": "2025-12-02T07:57:42.196818",
     "exception": false,
     "start_time": "2025-12-02T07:57:42.193355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14210809,
     "sourceId": 114239,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27.18776,
   "end_time": "2025-12-02T07:57:44.543182",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-02T07:57:17.355422",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
